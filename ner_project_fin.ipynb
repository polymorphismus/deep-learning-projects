{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9b08e4-1014-4de4-9eb7-4dc74a501eeb",
   "metadata": {},
   "source": [
    "# Project overview\n",
    "Project Overview\n",
    "\n",
    "Named Entity Recognition models are typically trained on a specific dataset with its own label definitions, tokenization patterns, and annotation rules. When such a model is applied to a different dataset, a common but often overlooked issue appears: the label spaces do not match.\n",
    "This project investigates these underlying issues:\n",
    "* How mismatched label spaces distort predictions, especially when the model assigns labels that the dataset does not define.\n",
    "* How subword tokenization complicates alignment, because entity tags must be mapped from words to subtokens in a consistent and loss-aware way.\n",
    "* Why naïvely fine-tuning a pretrained NER model may fail, if parts of its classifier head receive no supervision.\n",
    "\n",
    "The goal is to examine these challenges directly, understand how they manifest in predictions, and show why resolving label-space alignment is essential before any meaningful fine-tuning can occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9820ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch] datasets evaluate seqeval torch matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3608e36b-a638-4345-ba54-42547a86a3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    default_data_collator,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe9ac0-6fb0-4c48-b388-83712f0b2181",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) with Cross-Dataset Label Mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947591f-d4ad-4d60-b4a7-53b632dc9c21",
   "metadata": {},
   "source": [
    "#### WikiANN Dataset\n",
    "The WikiANN dataset contains Wikipedia sentences annotated for NER containing word tokens, ner_tags, languages and readable spans. Lets look inside "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bac035fe-ed5b-40bc-b21c-164d4fce4c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n",
      "\n",
      "Split: validation\n",
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Example sample: {'tokens': ['Sioux', 'Falls', 'Arena', '(', 'Sioux', 'Falls', ',', 'South', 'Dakota', ')'], 'ner_tags': [3, 4, 4, 0, 5, 6, 6, 6, 6, 0], 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en'], 'spans': ['ORG: Sioux Falls Arena', 'LOC: Sioux Falls , South Dakota']}\n",
      "\n",
      "Split: test\n",
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Example sample: {'tokens': ['Shortly', 'afterward', ',', 'an', 'encouraging', 'response', 'influenced', 'him', 'to', 'go', 'to', 'India', ';', 'he', 'arrived', 'at', 'Adyar', 'in', '1884', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0], 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en'], 'spans': ['LOC: India', 'LOC: Adyar']}\n",
      "\n",
      "Split: train\n",
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "    num_rows: 20000\n",
      "})\n",
      "Example sample: {'tokens': ['R.H.', 'Saunders', '(', 'St.', 'Lawrence', 'River', ')', '(', '968', 'MW', ')'], 'ner_tags': [3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0], 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en'], 'spans': ['ORG: R.H. Saunders', 'ORG: St. Lawrence River']}\n"
     ]
    }
   ],
   "source": [
    "wikiann = load_dataset(\"wikiann\", \"en\")\n",
    "\n",
    "print(wikiann)\n",
    "\n",
    "for split in wikiann.keys():\n",
    "    print(f\"\\nSplit: {split}\")\n",
    "    print(wikiann[split])\n",
    "    print(\"Example sample:\", wikiann[split][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1fa754-e025-4892-8bb4-5899c14a6412",
   "metadata": {},
   "source": [
    "Understanding 1st example:\n",
    "\n",
    "The sentence in validation is split into tokens:\n",
    "[\"Sioux\", \"Falls\", \"Arena\", \"(\", \"Sioux\", \"Falls\", \",\", \"South\", \"Dakota\", \")\"]\n",
    "\n",
    "ner_tags correspond to each token using integer IDs:\n",
    "* 0 → O (not an entity)\n",
    "* 3 → B-ORG\n",
    "* 4 → I-ORG\n",
    "* 5 → B-LOC\n",
    "* 6 → I-LOC\n",
    "\n",
    "So:\n",
    "\n",
    "* \"Sioux\" → tag 3 → B-ORG\n",
    "* \"Falls\" → tag 4 → I-ORG\n",
    "* \"Arena\" → tag 4 → I-ORG\n",
    "\n",
    "=> the entity ORG: Sioux Falls Arena\n",
    "\n",
    "\n",
    "Lets map dictionaries from the lable names and integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43408321-7407-46da-a8c6-f102d8b64945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'O',\n",
       "  1: 'B-PER',\n",
       "  2: 'I-PER',\n",
       "  3: 'B-ORG',\n",
       "  4: 'I-ORG',\n",
       "  5: 'B-LOC',\n",
       "  6: 'I-LOC'},\n",
       " {'O': 0,\n",
       "  'B-PER': 1,\n",
       "  'I-PER': 2,\n",
       "  'B-ORG': 3,\n",
       "  'I-ORG': 4,\n",
       "  'B-LOC': 5,\n",
       "  'I-LOC': 6})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiann_label_names = wikiann[\"train\"].features[\"ner_tags\"].feature.names\n",
    "wikiann_id2label: Dict[int, str] = {i: name for i, name in enumerate(wikiann_label_names)}\n",
    "wikiann_label2id: Dict[str, int] = {name: i for i, name in wikiann_id2label.items()}\n",
    "wikiann_id2label, wikiann_label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6b29d-0993-4f04-90dc-9909df21e69c",
   "metadata": {},
   "source": [
    "### Label distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6028f2d8-e4d2-4c1b-92e4-ff3b40c6fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts across all WikiANN splits:\n",
      "O      : 163071\n",
      "I-ORG  : 46471\n",
      "I-PER  : 29698\n",
      "I-LOC  : 25981\n",
      "B-ORG  : 18844\n",
      "B-LOC  : 18836\n",
      "B-PER  : 18355\n"
     ]
    }
   ],
   "source": [
    "all_tags = []\n",
    "\n",
    "for split in wikiann.keys():\n",
    "    ds_split = wikiann[split]\n",
    "    for example in ds_split:\n",
    "        all_tags.extend(example[\"ner_tags\"])\n",
    "\n",
    "tag_names = [wikiann_id2label[tag_id] for tag_id in all_tags]\n",
    "tag_counts = Counter(tag_names)\n",
    "\n",
    "print(\"Label counts across all WikiANN splits:\")\n",
    "for label, count in tag_counts.most_common():\n",
    "    print(f\"{label:7}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "252048bf-59da-458f-84eb-b2c98dd63d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGGCAYAAABmPbWyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAARYpJREFUeJzt3Xl4jPf+//HXJLJHQiyxpZaiRC0VW7SnpY2kqFYbLV1DVcvBKTmlR6m1jlaPrcShtZ6iVDctiqCqdlKx02opF4LWEgmSSO7fH74zv4xJ4hbDTHg+rmuudu77c9/3+/7MJ8nLvY3FMAxDAAAAKJCHqwsAAAAoCghNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITcAttmbNGlksFq1Zs8Y2rUWLFrr//vuvu2yVKlXUuXPnW1ccblrnzp0VGBjo1HW2aNFCLVq0cOo6rSwWi4YOHXpL1p3bzYx7Zzh8+LAsFotmzZp1W7aHuwOhCSjA559/LovFoq+//tphXv369WWxWPTDDz84zLvnnnvUvHnzW1rb0qVLZbFYVKFCBeXk5OTZpkqVKrJYLOrdu7fDPOsftS+++MI2bdasWbJYLPL19dWxY8ccljH7R69z586yWCyqV6+e8vqmJovFol69etneW//A5fd6//337WrIPc/Pz0/16tXT+PHj8+2Ha1WpUkVPPPGEqbbuzPr5WiwWeXh4qESJEqpbt65ef/11bd682WnbmTdvnsaPH++09TmTO9eGO08xVxcAuLOHHnpIkrRu3To9/fTTtumpqanavXu3ihUrpvXr16tly5a2eUePHtXRo0fVqVMnSdLDDz+sS5cuydvb+4a3f+DAAXl45P1vm7lz56pKlSo6fPiwVq9eraioqHzX88knn2jAgAGqUKGCqe1mZGTo/fff18SJE2+45tx27dqlr776SrGxsabaP//882rTpo3D9AceeMDufaVKlTRq1ChJ0p9//ql58+apb9++On36tEaOHHlTNRc1DRo00D//+U9J0oULF7Rv3z4tXLhQn3zyifr27auxY8fatb906ZKKFbuxX/3z5s3T7t271adPH9PL3My4vxH51Va5cmVdunRJXl5et3T7uLsQmoACVKhQQVWrVtW6devspm/cuFGGYejZZ591mGd9bw1cHh4e8vX1LdT2fXx88pyenp6uRYsWadSoUZo5c6bmzp2bb2iqU6eODhw4oPfff18fffSRqe02aNDghoPWtfz8/BQWFqbhw4frmWeekcViue4yDRs21EsvvXTddsHBwXbtunfvrlq1amnixIkaPny4PD09C1VzUVSxYkWHPvvggw/0wgsvaNy4capRo4Z69Ohhm1fYsWjW5cuX5e3tfVPj3hmsR0wBZ+L0HHAdDz30kLZv365Lly7Zpq1fv1516tRR69attWnTJrvTQuvXr5fFYtGDDz4oKe9rO/KyYsUK+fv76/nnn9eVK1ck5X9N09dff61Lly7p2WefVadOnfTVV1/p8uXLea63SpUqeuWVV/TJJ5/o+PHjpvb5nXfeUXZ2tt1psRvl4eGhQYMGaefOnXme3nQmX19fNW7cWBcuXNCpU6ecss6ffvpJzz77rO655x75+PgoLCxMffv2tRsHuf3++++KiYlRQECAKlSooOHDhzucmszJydH48eNVp04d+fr6KjQ0VG+88YbOnj3rlJqt/Pz89OmnnyokJEQjR460q+Paa5ouXLigPn36qEqVKvLx8VHZsmXVqlUr/fzzz5Kung5dsmSJ/vjjD9upwCpVqkj6/2N7/vz5GjRokCpWrCh/f3+lpqYWOO6TkpLUvHlz+fn5qWrVqpoyZYrdfOtp4sOHD9tNv3adBdWW3zVNq1ev1t/+9jcFBASoRIkSeuqpp7Rv3z67NkOHDpXFYtHBgwfVuXNnlShRQsHBwerSpYsuXrxo7kPAHYnQBFzHQw89pKysLLtrRNavX6/mzZurefPmOn/+vHbv3m03r1atWipVqpTpbSxevFhPPvmknn32Wc2ZM+e6p0/mzp2rli1bqly5curUqZMuXLig7777Lt/2AwcO1JUrV0yHoKpVq95w0MrLCy+8oBo1auQZIPJy8eJF/fnnnw4va4gsiPWPZIkSJQpdb24LFy7UxYsX1aNHD02cOFExMTGaOHGiXnnlFYe22dnZevzxxxUaGqrRo0crIiJCQ4YM0ZAhQ+zavfHGG+rXr58efPBBTZgwQV26dNHcuXMVExOjrKwsp9RtFRgYqKefflrHjh3T3r17823XvXt3/fe//1VsbKwmT56st956S35+frYgMXDgQDVo0EClS5fWp59+qk8//dThGqIRI0ZoyZIleuutt/Tvf/+7wFNyZ8+eVZs2bRQREaHRo0erUqVK6tGjh2bMmHHD+2imttxWrlypmJgYnTp1SkOHDlV8fLw2bNigBx980CGgSdJzzz2nCxcuaNSoUXruuec0a9YsDRs27IbrxB3EAFCgPXv2GJKMESNGGIZhGFlZWUZAQIAxe/ZswzAMIzQ01EhISDAMwzBSU1MNT09Po1u3brblf/jhB0OS8cMPP9imPfLII0adOnUMwzCML7/80vDy8jK6detmZGdn2227cuXKRlxcnN20kydPGsWKFTM++eQT27TmzZsbTz31lEPtlStXNtq2bWsYhmF06dLF8PX1NY4fP25X18KFC23tZ86caUgytm7davz2229GsWLFjH/84x951l2QuLg4IyAgwDAMw5g9e7Yhyfjqq69s8yUZPXv2tL0/dOiQISnf18aNG+1qqFWrlnH69Gnj9OnTxv79+41+/foZkmz7ej25+yU/Fy9edJg2atQow2KxGH/88YfdvkoyevfubZuWk5NjtG3b1vD29jZOnz5tGIZh/PTTT4YkY+7cuXbrXLZsmcP0Rx55xHjkkUduej/GjRtnSDIWLVpkmybJGDJkiO19cHCw3WeRl7Zt2xqVK1d2mG4dQ9WqVXPor/zGvSRjzJgxtmkZGRlGgwYNjLJlyxqZmZmGYfz/cXjo0KHrrjO/2qxjaubMmbZp1u389ddftmk7duwwPDw8jFdeecU2bciQIYYk49VXX7Vb59NPP22UKlXKYVu4e3CkCbiO2rVrq1SpUrZrlXbs2KH09HTb3XHNmzfX+vXrJV291ik7O9t2PdP1fPbZZ+rYsaPeeOMNTZ06Nd+LvnObP3++PDw87C6ufv755/X9998XeJpn0KBBN3S0qVq1anr55Zf18ccf68SJE6aWycuLL75o+mjT66+/rsTERIdXeHi4Xbv9+/erTJkyKlOmjGrVqqUPP/xQTz75pFNvL/fz87P9f3p6uv788081b95chmFo+/btDu1z3w1ovTswMzNTK1eulHT1yFVwcLBatWpldxQtIiJCgYGBed6FebOsj0K4cOFCvm1KlCihzZs339QRxbi4OLv+KkixYsX0xhtv2N57e3vrjTfe0KlTp5SUlFToGq7nxIkTSk5OVufOnRUSEmKbXq9ePbVq1UpLly51WKZ79+527//2t7/pr7/+Umpq6i2rE+6N0ARch8ViUfPmzW3XLq1fv15ly5ZV9erVJdmHJut/zYSmQ4cO6aWXXlJsbKwmTpxo6kJpSZozZ46aNGmiv/76SwcPHtTBgwf1wAMPKDMzUwsXLsx3ucKEoBsNWnnx9PTUoEGDlJycrG+++abAtjVq1FBUVJTDKygoyK5dlSpVlJiYqOXLl2vy5MmqWLGiTp8+7dQLf48cOWL7AxsYGKgyZcrokUcekSSdP3/erq2Hh4eqVatmN61mzZqSZDvt8+uvv+r8+fMqW7asLfBZX2lpaU67Fiu3tLQ0SVLx4sXzbTN69Gjt3r1bYWFhatKkiYYOHarff//9hrZTtWpV020rVKiggIAAu2nX9tWt8Mcff0iS7rvvPod5tWvX1p9//qn09HS76ffcc4/d+5IlS0qS069BQ9FBaAJMeOihh3T+/Hnt2rXLdj2TVfPmzfXHH3/o2LFjWrdunSpUqODwBzQv5cuXV/PmzbV06VJt27bNVB2//vqrtm7dqnXr1qlGjRq2lzWkzZ07t8Dlrdc2ffDBB6a2V61aNb300ktOOdpUvXp109c2XU9AQICioqIUHR2tHj16aOnSpdqyZYveeeedm163dPUapVatWmnJkiV6++239c033ygxMdF2JMvs86Byy8nJUdmyZfM8kpaYmKjhw4c7pfbcrNfaWQN+Xp577jn9/vvvmjhxoipUqKAPP/xQderU0ffff296O2aPMpmV3z8gsrOznbqd68nvLkxnjGEUTTxyADAh9/Oa1q9fb/dMmIiICPn4+GjNmjXavHlzns8Zyouvr68WL16sRx99VI8//rh+/PFH1alTp8Bl5s6dKy8vL3366acOv9DXrVunjz76SEeOHHH4F7LVvffeq5deeklTp05V06ZNTdU5aNAgzZkzx3TQyov1aFPnzp21aNGiQq8nP/Xq1bPt11tvvZXv/pu1a9cu/fLLL5o9e7bdhd+JiYl5ts/JydHvv/9uO2IiSb/88osk2e7muvfee7Vy5Uo9+OCDTg8ZeUlLS9PXX3+tsLAw1a5du8C25cuX19///nf9/e9/16lTp9SwYUONHDlSrVu3lpR/iCmM48ePKz093e5o07V9ZT2ic+7cObtlrUeLcjNbW+XKlSVdffbZtfbv36/SpUs7HAEDrsWRJsCERo0aydfXV3PnztWxY8fsjjT5+PioYcOGSkhIUHp6uunrmaSrzxtavny57Tbv3377rcD2c+fO1d/+9jd17NhRHTp0sHv169dP0tXrpAoyaNAgZWVlafTo0aZqzB20UlJSzO1YHl566SVVr179lt191L9/f2VlZTk8zLEwrIE09xEFwzA0YcKEfJeZNGmSXdtJkybJy8tLjz32mKSrR3Sys7M1YsQIh2WvXLniEBBuxqVLl/Tyyy/rzJkzGjhwYIFHbq491Vi2bFlVqFBBGRkZtmkBAQEO7QrrypUrmjp1qu19Zmampk6dqjJlyigiIkLS1TEnSWvXrrWr9eOPP3ZYn9naypcvrwYNGmj27Nl2fb17926tWLHC9D92cHfjSBNggre3txo3bqyffvpJPj4+tl/uVs2bN9eYMWMkmbueKbfSpUsrMTFRDz30kKKiorRu3TpVrFjRod3mzZt18OBBuwuOc6tYsaIaNmyouXPn6u233853e9YQNHv2bNM1Dhw4UJ9++qkOHDhw3aNh+fH09NTAgQPVpUuXfNv8/PPPmjNnTp41R0ZGFrj+8PBwtWnTRtOmTdO777573Uc+HDx4UO+9957D9AceeEDR0dG699579dZbb+nYsWMKCgrSl19+me+1LL6+vlq2bJni4uLUtGlTff/991qyZIneeecdlSlTRpL0yCOP6I033tCoUaOUnJys6OhoeXl56ddff9XChQs1YcIEdejQocCa83Ls2DFbn6WlpWnv3r1auHChUlJS9M9//tPuoutrXbhwQZUqVVKHDh1Uv359BQYGauXKldq6dattPEtXj6YuWLBA8fHxaty4sQIDA9WuXbsbrlW6ek3TBx98oMOHD6tmzZpasGCBkpOT9fHHH9ue3l2nTh01a9ZMAwYM0JkzZxQSEqL58+fn+eiJG6ntww8/VOvWrRUZGamuXbvq0qVLmjhxooKDg2/L9/HhDuDCO/eAImXAgAGGJKN58+YO87766itDklG8eHHjypUrdvOu98gBq4MHDxrly5c3ateubbtNPfcjB3r37m1IMn777bd8axw6dKghydixY4dt+bxuSf/1118NT0/PAh85cC3rrfU3+siB3LKysox77733hh85kPuxCwU99mDNmjUOt9TnpXLlyvluq2vXroZhGMbevXuNqKgoIzAw0ChdurTRrVs3Y8eOHQ63sVv39bfffjOio6MNf39/IzQ01BgyZIjDIyQMwzA+/vhjIyIiwvDz8zOKFy9u1K1b1+jfv7/tURDWfTT7yAFr3RaLxQgKCjLq1KljdOvWzdi8eXOey+Tun4yMDKNfv35G/fr1jeLFixsBAQFG/fr1jcmTJ9stk5aWZrzwwgtGiRIlDEm2W/zzemyFVUHjftu2bUZkZKTh6+trVK5c2Zg0aZLD8r/99psRFRVl+Pj4GKGhocY777xjJCYmOqwzv9ryeuSAYRjGypUrjQcffNDw8/MzgoKCjHbt2hl79+61a2N95ID159Aqv0ch4O5hMQyuaAMAALgermkCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJvBwSyfJycnR8ePHVbx4cad+5QAAALi1DMPQhQsXVKFCBXl45H88idDkJMePH1dYWJirywAAAIV09OhRVapUKd/5hCYnKV68uKSrHR4UFOTiavKXlZWlFStW2L7CAYVDPzoPfek89KXz0JfOUxT6MjU1VWFhYba/5fkhNDmJ9ZRcUFCQ24cmf39/BQUFue3gLQroR+ehL52HvnQe+tJ5ilJfXu/yGi4EBwAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJfGEviqSIfv9z6fa9PaV/RQbr4Xc/U2a26+pI+vAV120cAO4yHGkCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwAS3CU3vv/++LBaL+vTpY5t2+fJl9ezZU6VKlVJgYKBiY2N18uRJu+WOHDmitm3byt/fX2XLllW/fv105coVuzZr1qxRw4YN5ePjo+rVq2vWrFkO209ISFCVKlXk6+urpk2basuWLbdiNwEAQBHlFqFp69atmjp1qurVq2c3vW/fvvruu++0cOFC/fjjjzp+/LieeeYZ2/zs7Gy1bdtWmZmZ2rBhg2bPnq1Zs2Zp8ODBtjaHDh1S27Zt1bJlSyUnJ6tPnz567bXXtHz5clubBQsWKD4+XkOGDNHPP/+s+vXrKyYmRqdOnbr1Ow8AAIoEl4emtLQ0vfjii/rkk09UsmRJ2/Tz589r+vTpGjt2rB599FFFRERo5syZ2rBhgzZt2iRJWrFihfbu3as5c+aoQYMGat26tUaMGKGEhARlZmZKkqZMmaKqVatqzJgxql27tnr16qUOHTpo3Lhxtm2NHTtW3bp1U5cuXRQeHq4pU6bI399fM2bMuL2dAQAA3FYxVxfQs2dPtW3bVlFRUXrvvfds05OSkpSVlaWoqCjbtFq1aumee+7Rxo0b1axZM23cuFF169ZVaGiorU1MTIx69OihPXv26IEHHtDGjRvt1mFtYz0NmJmZqaSkJA0YMMA238PDQ1FRUdq4cWO+dWdkZCgjI8P2PjU1VZKUlZWlrKyswnXGbWCtzZ1rNMPb0z227+o6ivrnKN05Y9Id0JfOQ186T1HoS7O1uTQ0zZ8/Xz///LO2bt3qMC8lJUXe3t4qUaKE3fTQ0FClpKTY2uQOTNb51nkFtUlNTdWlS5d09uxZZWdn59lm//79+dY+atQoDRs2zGH6ihUr5O/vn+9y7iIxMdHVJdyUf0UGu7oESVJ8E9fWsXTpUpdu35mK+ph0J/Sl89CXzuPOfXnx4kVT7VwWmo4ePao333xTiYmJ8vX1dVUZhTZgwADFx8fb3qempiosLEzR0dEKCgpyYWUFy8rKUmJiolq1aiUvLy9Xl1NoD7/7mUu37+15NTCN3XJemdmuq2PtiOddt3EnuVPGpDugL52HvnSeotCX1rNF1+Oy0JSUlKRTp06pYcOGtmnZ2dlau3atJk2apOXLlyszM1Pnzp2zO9p08uRJlStXTpJUrlw5h7vcrHfX5W5z7R13J0+eVFBQkPz8/OTp6SlPT88821jXkRcfHx/5+Pg4TPfy8nLbQZFbUakzP64MKrllZru2lqL8GV6rqI9Jd0JfOg996Tzu3Jdm63LZheCPPfaYdu3apeTkZNurUaNGevHFF23/7+XlpVWrVtmWOXDggI4cOaLIyEhJUmRkpHbt2mV3l1tiYqKCgoIUHh5ua5N7HdY21nV4e3srIiLCrk1OTo5WrVplawMAAOCyI03FixfX/fffbzctICBApUqVsk3v2rWr4uPjFRISoqCgIPXu3VuRkZFq1qyZJCk6Olrh4eF6+eWXNXr0aKWkpGjQoEHq2bOn7ShQ9+7dNWnSJPXv31+vvvqqVq9erc8//1xLliyxbTc+Pl5xcXFq1KiRmjRpovHjxys9PV1dunS5Tb0BAADcncvvnivIuHHj5OHhodjYWGVkZCgmJkaTJ0+2zff09NTixYvVo0cPRUZGKiAgQHFxcRo+fLitTdWqVbVkyRL17dtXEyZMUKVKlTRt2jTFxMTY2nTs2FGnT5/W4MGDlZKSogYNGmjZsmUOF4cDAIC7l1uFpjVr1ti99/X1VUJCghISEvJdpnLlyte9g6hFixbavn17gW169eqlXr16ma4VAADcXVz+cEsAAICigNAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABJeGpv/+97+qV6+egoKCFBQUpMjISH3//fe2+ZcvX1bPnj1VqlQpBQYGKjY2VidPnrRbx5EjR9S2bVv5+/urbNmy6tevn65cuWLXZs2aNWrYsKF8fHxUvXp1zZo1y6GWhIQEValSRb6+vmratKm2bNlyS/YZAAAUTS4NTZUqVdL777+vpKQkbdu2TY8++qieeuop7dmzR5LUt29ffffdd1q4cKF+/PFHHT9+XM8884xt+ezsbLVt21aZmZnasGGDZs+erVmzZmnw4MG2NocOHVLbtm3VsmVLJScnq0+fPnrttde0fPlyW5sFCxYoPj5eQ4YM0c8//6z69esrJiZGp06dun2dAQAA3JpLQ1O7du3Upk0b1ahRQzVr1tTIkSMVGBioTZs26fz585o+fbrGjh2rRx99VBEREZo5c6Y2bNigTZs2SZJWrFihvXv3as6cOWrQoIFat26tESNGKCEhQZmZmZKkKVOmqGrVqhozZoxq166tXr16qUOHDho3bpytjrFjx6pbt27q0qWLwsPDNWXKFPn7+2vGjBku6RcAAOB+3OaapuzsbM2fP1/p6emKjIxUUlKSsrKyFBUVZWtTq1Yt3XPPPdq4caMkaePGjapbt65CQ0NtbWJiYpSammo7WrVx40a7dVjbWNeRmZmppKQkuzYeHh6KioqytQEAACjm6gJ27dqlyMhIXb58WYGBgfr6668VHh6u5ORkeXt7q0SJEnbtQ0NDlZKSIklKSUmxC0zW+dZ5BbVJTU3VpUuXdPbsWWVnZ+fZZv/+/fnWnZGRoYyMDNv71NRUSVJWVpaysrJuoAduL2tt7lyjGd6e7rF9V9dR1D9H6c4Zk+6AvnQe+tJ5ikJfmq3N5aHpvvvuU3Jyss6fP68vvvhCcXFx+vHHH11d1nWNGjVKw4YNc5i+YsUK+fv7u6CiG5OYmOjqEm7KvyKDXV2CJCm+iWvrWLp0qUu370xFfUy6E/rSeehL53Hnvrx48aKpdi4PTd7e3qpevbokKSIiQlu3btWECRPUsWNHZWZm6ty5c3ZHm06ePKly5cpJksqVK+dwl5v17rrcba694+7kyZMKCgqSn5+fPD095enpmWcb6zryMmDAAMXHx9vep6amKiwsTNHR0QoKCrrBXrh9srKylJiYqFatWsnLy8vV5RTaw+9+5tLte3teDUxjt5xXZrbr6lg74nnXbdxJ7pQx6Q7oS+e5U/rS1b8rpaLx+9J6tuh6XB6arpWTk6OMjAxFRETIy8tLq1atUmxsrCTpwIEDOnLkiCIjIyVJkZGRGjlypE6dOqWyZctKuppkg4KCFB4ebmtz7b/GExMTbevw9vZWRESEVq1apfbt29tqWLVqlXr16pVvnT4+PvLx8XGY7uXlVSR+wIpKnflx5Q9ebpnZrq2lKH+G1yrqY9Kd0JfOU9T70l1+V0ru/fvS7Gfs0tA0YMAAtW7dWvfcc48uXLigefPmac2aNVq+fLmCg4PVtWtXxcfHKyQkREFBQerdu7ciIyPVrFkzSVJ0dLTCw8P18ssva/To0UpJSdGgQYPUs2dPW6Dp3r27Jk2apP79++vVV1/V6tWr9fnnn2vJkiW2OuLj4xUXF6dGjRqpSZMmGj9+vNLT09WlSxeX9AsAAHA/Lg1Np06d0iuvvKITJ04oODhY9erV0/Lly9WqVStJ0rhx4+Th4aHY2FhlZGQoJiZGkydPti3v6empxYsXq0ePHoqMjFRAQIDi4uI0fPhwW5uqVatqyZIl6tu3ryZMmKBKlSpp2rRpiomJsbXp2LGjTp8+rcGDByslJUUNGjTQsmXLHC4OBwAAdy+Xhqbp06cXON/X11cJCQlKSEjIt03lypWvezFsixYttH379gLb9OrVq8DTcQAA4O7mNs9pAgAAcGeEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATChWaqlWrpr/++sth+rlz51StWrWbLgoAAMDdFCo0HT58WNnZ2Q7TMzIydOzYsZsuCgAAwN3c0Bf2fvvtt7b/X758uYKDg23vs7OztWrVKlWpUsVpxQEAALiLGwpN7du3lyRZLBbFxcXZzfPy8lKVKlU0ZswYpxUHAADgLm4oNOXk5EiSqlatqq1bt6p06dK3pCgAAAB3c0OhyerQoUPOrgMAAMCtFSo0SdKqVau0atUqnTp1ynYEymrGjBk3XRgAAIA7KVRoGjZsmIYPH65GjRqpfPnyslgszq4LAADArRQqNE2ZMkWzZs3Syy+/7Ox6AAAA3FKhQlNmZqaaN2/u7FoAoEiL6Pc/l27f21P6V2SwHn73M2U6Pkrvtkn68BXXbRy4hQr1cMvXXntN8+bNc3YtAAAAbqtQR5ouX76sjz/+WCtXrlS9evXk5eVlN3/s2LFOKQ4AAMBdFCo07dy5Uw0aNJAk7d69224eF4UDAIA7UaFC0w8//ODsOgAAANxaoa5pAgAAuNsU6khTy5YtCzwNt3r16kIXBAAA4I4KFZqs1zNZZWVlKTk5Wbt373b4Il8AAIA7QaFC07hx4/KcPnToUKWlpd1UQQAAAO7Iqdc0vfTSS3zvHAAAuCM5NTRt3LhRvr6+zlwlAACAWyjU6blnnnnG7r1hGDpx4oS2bdumd9991ymFAQAAuJNChabg4GC79x4eHrrvvvs0fPhwRUdHO6UwAAAAd1Ko0DRz5kxn1wEAAODWChWarJKSkrRv3z5JUp06dfTAAw84pSgAAAB3U6jQdOrUKXXq1Elr1qxRiRIlJEnnzp1Ty5YtNX/+fJUpU8aZNQIAALhcoe6e6927ty5cuKA9e/bozJkzOnPmjHbv3q3U1FT94x//cHaNAAAALleoI03Lli3TypUrVbt2bdu08PBwJSQkcCE4AAC4IxXqSFNOTo68vLwcpnt5eSknJ+emiwIAAHA3hQpNjz76qN58800dP37cNu3YsWPq27evHnvsMacVBwAA4C4KFZomTZqk1NRUValSRffee6/uvfdeVa1aVampqZo4caKzawQAAHC5Ql3TFBYWpp9//lkrV67U/v37JUm1a9dWVFSUU4sDAABwFzd0pGn16tUKDw9XamqqLBaLWrVqpd69e6t3795q3Lix6tSpo59++ulW1QoAAOAyNxSaxo8fr27duikoKMhhXnBwsN544w2NHTvWacUBAAC4ixsKTTt27NDjjz+e7/zo6GglJSXddFEAAADu5oZC08mTJ/N81IBVsWLFdPr06ZsuCgAAwN3cUGiqWLGidu/ene/8nTt3qnz58jddFAAAgLu5odDUpk0bvfvuu7p8+bLDvEuXLmnIkCF64oknnFYcAACAu7ihRw4MGjRIX331lWrWrKlevXrpvvvukyTt379fCQkJys7O1sCBA29JoQAAAK50Q6EpNDRUGzZsUI8ePTRgwAAZhiFJslgsiomJUUJCgkJDQ29JoQAAAK50ww+3rFy5spYuXaqzZ8/q4MGDMgxDNWrUUMmSJW9FfQAAAG6hUE8El6SSJUuqcePGzqwFAADAbRXqu+ecZdSoUWrcuLGKFy+usmXLqn379jpw4IBdm8uXL6tnz54qVaqUAgMDFRsbq5MnT9q1OXLkiNq2bSt/f3+VLVtW/fr105UrV+zarFmzRg0bNpSPj4+qV6+uWbNmOdSTkJCgKlWqyNfXV02bNtWWLVucvs8AAKBocmlo+vHHH9WzZ09t2rRJiYmJysrKUnR0tNLT021t+vbtq++++04LFy7Ujz/+qOPHj+uZZ56xzc/Ozlbbtm2VmZmpDRs2aPbs2Zo1a5YGDx5sa3Po0CG1bdtWLVu2VHJysvr06aPXXntNy5cvt7VZsGCB4uPjNWTIEP3888+qX7++YmJidOrUqdvTGQAAwK0V+vScMyxbtszu/axZs1S2bFklJSXp4Ycf1vnz5zV9+nTNmzdPjz76qCRp5syZql27tjZt2qRmzZppxYoV2rt3r1auXKnQ0FA1aNBAI0aM0Ntvv62hQ4fK29tbU6ZMUdWqVTVmzBhJV79ceN26dRo3bpxiYmIkSWPHjlW3bt3UpUsXSdKUKVO0ZMkSzZgxQ//6179uY68AAAB35NIjTdc6f/68JCkkJESSlJSUpKysLEVFRdna1KpVS/fcc482btwoSdq4caPq1q1rd9deTEyMUlNTtWfPHlub3OuwtrGuIzMzU0lJSXZtPDw8FBUVZWsDAADubi490pRbTk6O+vTpowcffFD333+/JCklJUXe3t4qUaKEXdvQ0FClpKTY2lz7mAPr++u1SU1N1aVLl3T27FllZ2fn2Wb//v151puRkaGMjAzb+9TUVElSVlaWsrKybmTXbytrbe5coxnenu6xfVfXUdQ/R+nOGZOS68cD49J57pRx6eqxkLsGV9dS0Gdp9nN2m9DUs2dP7d69W+vWrXN1KaaMGjVKw4YNc5i+YsUK+fv7u6CiG5OYmOjqEm7KvyKDXV2CJCm+iWvrWLp0qUu370xFfUxKjEsrxqX7cJcxKbn3uLx48aKpdbhFaOrVq5cWL16stWvXqlKlSrbp5cqVU2Zmps6dO2d3tOnkyZMqV66crc21d7lZ767L3ebaO+5OnjypoKAg+fn5ydPTU56ennm2sa7jWgMGDFB8fLztfWpqqsLCwhQdHa2goKAb7IHbJysrS4mJiWrVqlWBX77s7h5+9zOXbt/b8+ovgLFbzisz23V1rB3xvOs27iR3ypiUGJdWjEv34eoxKRWNcWk9W3Q9Lg1NhmGod+/e+vrrr7VmzRpVrVrVbn5ERIS8vLy0atUqxcbGSpIOHDigI0eOKDIyUpIUGRmpkSNH6tSpUypbtqykq/8yCAoKUnh4uK3NtQkzMTHRtg5vb29FRERo1apVat++vaSrpwtXrVqlXr165Vm7j4+PfHx8HKZ7eXkViR+wolJnflz5g5dbZrZraynKn+G1ivqYlBiXVkX9c8ytqI9LdxmTknuPS7OfsUtDU8+ePTVv3jwtWrRIxYsXt12DFBwcLD8/PwUHB6tr166Kj49XSEiIgoKC1Lt3b0VGRqpZs2aSpOjoaIWHh+vll1/W6NGjlZKSokGDBqlnz562UNO9e3dNmjRJ/fv316uvvqrVq1fr888/15IlS2y1xMfHKy4uTo0aNVKTJk00fvx4paen2+6mAwAAdzeXhqb//ve/kqQWLVrYTZ85c6Y6d+4sSRo3bpw8PDwUGxurjIwMxcTEaPLkyba2np6eWrx4sXr06KHIyEgFBAQoLi5Ow4cPt7WpWrWqlixZor59+2rChAmqVKmSpk2bZnvcgCR17NhRp0+f1uDBg5WSkqIGDRpo2bJlfJceAACQ5Aan567H19dXCQkJSkhIyLeN9fvwCtKiRQtt3769wDa9evXK93QcAAC4u7nVc5oAAADclVvcPXe3iOj3P1eXIG/Pq7egPvzuZy69IC/pw1dct3HYcfW4ZEwCKCo40gQAAGACoQkAAMAETs8BANwOp42v4rSxe+FIEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYIJLQ9PatWvVrl07VahQQRaLRd98843dfMMwNHjwYJUvX15+fn6KiorSr7/+atfmzJkzevHFFxUUFKQSJUqoa9euSktLs2uzc+dO/e1vf5Ovr6/CwsI0evRoh1oWLlyoWrVqydfXV3Xr1tXSpUudvr8AAKDocmloSk9PV/369ZWQkJDn/NGjR+ujjz7SlClTtHnzZgUEBCgmJkaXL1+2tXnxxRe1Z88eJSYmavHixVq7dq1ef/112/zU1FRFR0ercuXKSkpK0ocffqihQ4fq448/trXZsGGDnn/+eXXt2lXbt29X+/bt1b59e+3evfvW7TwAAChSirly461bt1br1q3znGcYhsaPH69BgwbpqaeekiT973//U2hoqL755ht16tRJ+/bt07Jly7R161Y1atRIkjRx4kS1adNG//nPf1ShQgXNnTtXmZmZmjFjhry9vVWnTh0lJydr7NixtnA1YcIEPf744+rXr58kacSIEUpMTNSkSZM0ZcqU29ATAADA3bk0NBXk0KFDSklJUVRUlG1acHCwmjZtqo0bN6pTp07auHGjSpQoYQtMkhQVFSUPDw9t3rxZTz/9tDZu3KiHH35Y3t7etjYxMTH64IMPdPbsWZUsWVIbN25UfHy83fZjYmIcThfmlpGRoYyMDNv71NRUSVJWVpaysrLyXMbb84a64Jaw1uDqWvLrI7NcXf+d0o+S6/eBvnQe+tJ57pS+dHX9uWtwdS0F9aXZfnbb0JSSkiJJCg0NtZseGhpqm5eSkqKyZcvazS9WrJhCQkLs2lStWtVhHdZ5JUuWVEpKSoHbycuoUaM0bNgwh+krVqyQv79/nsv8KzI43/XdbvFNXFvLzV4z5i59WdT7UaIvrehL56EvnedO+V0puXdfXrx40dQ63DY0ubsBAwbYHZ1KTU1VWFiYoqOjFRQUlOcyD7/72e0qL1/enlcH7tgt55WZ7bo61o54/qaWd3Vf3in9KNGXVvSl89CXzlPUf1dKRaMvrWeLrsdtQ1O5cuUkSSdPnlT58uVt00+ePKkGDRrY2pw6dcpuuStXrujMmTO25cuVK6eTJ0/atbG+v14b6/y8+Pj4yMfHx2G6l5eXvLy88lzGlYPlWpnZrq0nvz4yy136sqj3o0RfWtGXzkNfOs+d8rtScu++NNvPbvucpqpVq6pcuXJatWqVbVpqaqo2b96syMhISVJkZKTOnTunpKQkW5vVq1crJydHTZs2tbVZu3at3fnKxMRE3XfffSpZsqStTe7tWNtYtwMAAODS0JSWlqbk5GQlJydLunrxd3Jyso4cOSKLxaI+ffrovffe07fffqtdu3bplVdeUYUKFdS+fXtJUu3atfX444+rW7du2rJli9avX69evXqpU6dOqlChgiTphRdekLe3t7p27ao9e/ZowYIFmjBhgt2ptTfffFPLli3TmDFjtH//fg0dOlTbtm1Tr169bneXAAAAN+XS03Pbtm1Ty5Ytbe+tQSYuLk6zZs1S//79lZ6ertdff13nzp3TQw89pGXLlsnX19e2zNy5c9WrVy899thj8vDwUGxsrD766CPb/ODgYK1YsUI9e/ZURESESpcurcGDB9s9y6l58+aaN2+eBg0apHfeeUc1atTQN998o/vvv/829AIAACgKXBqaWrRoIcMw8p1vsVg0fPhwDR8+PN82ISEhmjdvXoHbqVevnn766acC2zz77LN69tlnCy4YAADctdz2miYAAAB3QmgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqHpGgkJCapSpYp8fX3VtGlTbdmyxdUlAQAAN0BoymXBggWKj4/XkCFD9PPPP6t+/fqKiYnRqVOnXF0aAABwMUJTLmPHjlW3bt3UpUsXhYeHa8qUKfL399eMGTNcXRoAAHAxQtP/yczMVFJSkqKiomzTPDw8FBUVpY0bN7qwMgAA4A6KuboAd/Hnn38qOztboaGhdtNDQ0O1f/9+h/YZGRnKyMiwvT9//rwk6cyZM8rKyspzGx5XLjmx4sLxMKSLF73kceWSPLJdV8dff/11U8u7ui/vlH6U6Esr+tJ56EvnKeq/K6Wi0ZcXLlyQJBmGUfBKDBiGYRjHjh0zJBkbNmywm96vXz+jSZMmDu2HDBliSOLFixcvXrx43SGvo0ePFpgVONL0f0qXLi1PT0+dPHnSbvrJkydVrlw5h/YDBgxQfHy87X1OTo7OnDmjUqVKyWKx3PJ6Cys1NVVhYWE6evSogoKCXF1OkUU/Og996Tz0pfPQl85TFPrSMAxduHBBFSpUKLAdoen/eHt7KyIiQqtWrVL79u0lXQ1Cq1atUq9evRza+/j4yMfHx25aiRIlbkOlzhEUFOS2g7cooR+dh750HvrSeehL53H3vgwODr5uG0JTLvHx8YqLi1OjRo3UpEkTjR8/Xunp6erSpYurSwMAAC5GaMqlY8eOOn36tAYPHqyUlBQ1aNBAy5Ytc7g4HAAA3H0ITdfo1atXnqfj7hQ+Pj4aMmSIw6lF3Bj60XnoS+ehL52HvnSeO6kvLYZxvfvrAAAAwMMtAQAATCA0AQAAmEBoAgAAMIHQ5MY6d+4si8Vie5UqVUqPP/64du7ced1l9+zZo+eee05lypSRj4+PatasqcGDB+vixYt27apUqWJbv7+/v+rWratp06Y5rM8wDH3yySeKjIxUUFCQAgMDVadOHb355ps6ePCg0/b5VuvcubPtOVz5uXTpkoYMGaKaNWvKx8dHpUuX1rPPPqs9e/bYtRs6dKit7zw9PRUWFqbXX39dZ86ccVjn9u3b1bFjR5UvX14+Pj6qXLmynnjiCX333XfXf2y/GyrM2Dx8+LAsFouSk5PzbbNhwwa1adNGJUuWlK+vr+rWrauxY8cqO9vxuxd++OEHtWnTRqVKlZK/v7/Cw8P1z3/+U8eOHXPGLrrE9cZnixYt1KdPn3znnzlzRn369FHlypXl7e2tChUq6NVXX9WRI0cc2qakpKh3796qVq2afHx8FBYWpnbt2mnVqlVO2BPXuZmxmXuZ6Ohobd++3damRYsWdm2sr+7du9va5J4eFBSkxo0ba9GiRbd0f28HM+PSut++vr4KDw/X5MmTbfNnzZqVZ9/5+vrabcM63cvLS1WrVlX//v11+fLlW7lrN4zQ5OYef/xxnThxQidOnNCqVatUrFgxPfHEEwUus2nTJjVt2lSZmZlasmSJfvnlF40cOVKzZs1Sq1atlJmZadd++PDhOnHihHbv3q2XXnpJ3bp10/fff2+bbxiGXnjhBf3jH/9QmzZttGLFCu3du1fTp0+Xr6+v3nvvvVuy766QkZGhqKgozZgxQ++9955++eUXLV26VFeuXFHTpk21adMmu/Z16tTRiRMndOTIEc2cOVPLli1Tjx497NosWrRIzZo1U1pammbPnq19+/Zp2bJlevrppzVo0CDb9xYWNYUZmwX5+uuv9cgjj6hSpUr64YcftH//fr355pt677331KlTJ7twOXXqVEVFRalcuXL68ssvtXfvXk2ZMkXnz5/XmDFjnLF7Rc6ZM2fUrFkzrVy5UlOmTNHBgwc1f/58HTx4UI0bN9bvv/9ua3v48GFFRERo9erV+vDDD7Vr1y4tW7ZMLVu2VM+ePV24F85R2LG5cuVKnThxQsuXL1daWppat26tc+fO2eZ369bNtl7ra/To0XbrmDlzpk6cOKFt27bpwQcfVIcOHbRr1y5n76LbsfbN3r179dxzz6lnz5767LPPbPODgoIc+u6PP/6wW4f1c/v99981btw4TZ06VUOGDLndu1Iw53xzG26FuLg446mnnrKb9tNPPxmSjFOnTuW5TE5OjhEeHm40atTIyM7OtpuXnJxsWCwW4/3337dNq1y5sjFu3Di7diEhIUbfvn1t7z/77DNDkrFo0aJ8t1lU5NWnub3//vuGxWIxkpOT7aZnZ2cbjRo1MsLDw237O2TIEKN+/fp27eLj442SJUva3qelpRmlSpUynn766Xy3WZT6z6owY/PQoUOGJGP79u0O86z99MwzzzjM+/bbbw1Jxvz58w3DMIyjR48a3t7eRp8+ffLcztmzZ29oX9zJ9cbnI488Yrz55pt5zuvevbsREBBgnDhxwm76xYsXjYoVKxqPP/64bVrr1q2NihUrGmlpaQ7rKcr9ZxjOG5vr1683JBnLli0zDKPgvreSZHz99de296mpqYYkY8KECYXZFbdRmHFZo0YNo1OnToZhGMbMmTON4ODgG97GM888YzzwwAOFqPjW4UhTEZKWlqY5c+aoevXqKlWqVJ5tkpOTtXfvXsXHx8vDw/7jrV+/vqKiouzSf245OTn68ssvdfbsWXl7e9umf/bZZ7rvvvv05JNP5rmcO3/X3o2aN2+eWrVqpfr169tN9/DwUN++fbV3717t2LEjz2UPHz6s5cuX2/XdihUr9Ndff6l///75bvNO6D8zY7Mg1n566623HOa1a9dONWvWtI3bhQsXKjMzM98+LUpfZ+QsOTk5mj9/vl588UWH78r08/PT3//+dy1fvlxnzpzRmTNntGzZMvXs2VMBAQEO67rT+q+wY9PPz0+SHI7Mm3XlyhVNnz5dkux+J9wt/Pz8Ct13krR7925t2LDB7fqO0OTmFi9erMDAQAUGBqp48eL69ttvtWDBAodAZPXLL79IkmrXrp3n/Nq1a9vaWL399tsKDAyUj4+POnTooJIlS+q1116zW+d9991nt0yfPn1sdVWqVOlmdtGt/PLLLwX2nbWN1a5duxQYGCg/Pz9VrVpVe/bs0dtvv223Pkl2/bd161Zb3wUGBmrx4sW3YlduuRsdmwW53ritVauWrc2vv/6qoKAglS9fvvDF32FOnz6tc+fOFTh2DcPQwYMHdfDgQRmGoVq1at3mKm+fmx2b586d04gRIxQYGKgmTZrYpk+ePNnuZzcwMFBz5861W/b555+3/T7t27evqlSpoueee86p++fOsrOzNWfOHO3cuVOPPvqobfr58+cd+q5169Z2y1o/N+v1jKdOnVK/fv1u9y4UiNDk5lq2bKnk5GQlJydry5YtiomJUevWrfXHH3+odevWtsFXp04du+WMG7i4uF+/fkpOTtbq1avVtGlTjRs3TtWrVy9wmYEDByo5OVmDBw9WWlpaofbNlebOnWv3w/vTTz/Z5t1I3913331KTk7W1q1b9fbbbysmJka9e/cucJl69erZPtP09HRduXKl0PvhSoUdmwUx0/eGYdwRR+cKUtD4LIjZ/rvTFXZsNm/eXIGBgSpZsqR27NihBQsW2H2N1osvvmhbr/V17RH4cePGKTk5Wd9//73Cw8M1bdo0hYSE3Jb9vtUKGpfWQOnn56du3bqpb9++dtd3Fi9e3KHvrr3pyPq5bd68WXFxcerSpYtiY2Nv2/6ZwdeouLmAgAC7ADNt2jQFBwfrk08+0bRp03Tp0iVJkpeXlySpZs2akqR9+/bpgQcecFjfvn37bG2sSpcurerVq6t69epauHCh6tatq0aNGik8PFySVKNGDR04cMBumTJlyqhMmTIqW7as83b2NnryySfVtGlT2/uKFStKutp/+/bty3MZ6/Tc/eft7W37fN5//321bdtWw4YN04gRIyRd7TtJOnDggJo1aybp6lcKXC+UFgU3OjYLknvcNm/e3GH+vn37bOOxZs2aOn/+vE6cOHHHHm3Kb3zmp0yZMipRokSBY9disdg+L4vFov379zuvYDdT2LG5YMEChYeHq1SpUnmepgwODr7uz265cuVsv09nzpypNm3aaO/evUX2d2VuBY3LF198UQMHDpSfn5/Kly/vcFTPw8Pjun2X+3ObMWOG6tevr+nTp6tr165O3Iubw5GmIsZiscjDw0OXLl1SxYoVbT+clStXliQ1aNBAtWrV0rhx45STk2O37I4dO7Ry5Uo9//zz+a4/LCxMHTt21IABA2zTnn/+eR04cOCOuHXWqnjx4ra+q169uu36hU6dOmnlypUO1y3l5ORo3LhxCg8Pd7jeKbdBgwbpP//5j44fPy5Jio6OVkhIiD744INbtzNu4npjsyDWfsrrzrdvv/1Wv/76q23cdujQQd7e3g53LVnlvtupqMpvfObHw8NDzz33nObNm6eUlBS7eZcuXdLkyZMVExOjkJAQhYSEKCYmRgkJCUpPT3dY153Qf9cyOzbDwsJ07733Ou26riZNmigiIkIjR450yvpcraBxaQ2UFStWLNQp+mt5eHjonXfe0aBBg2wh1x0QmtxcRkaGUlJSlJKSon379ql3795KS0tTu3bt8mxvsVg0ffp07d27V7GxsdqyZYuOHDmihQsXql27doqMjCzwOS+S9Oabb+q7777Ttm3bJF0NEh06dFCnTp00fPhwbd68WYcPH9aPP/6oBQsWyNPT09m77TJ9+/ZVkyZN1K5dOy1cuFBHjhzR1q1bFRsbq3379mn69OkFnhqKjIxUvXr19O9//1uSFBgYqGnTpmnJkiVq27atli9frt9//107d+60/dEvqv13o2PT6sCBAw6H6b29vTV16lQtWrRIr7/+unbu3KnDhw9r+vTp6ty5szp06GC7LiQsLEzjxo3ThAkT1LVrV/3444/6448/tH79er3xxhu2o3x3qtOnTzv038mTJ/Xvf/9b5cqVU6tWrfT999/r6NGjWrt2rWJiYpSVlaWEhATbOhISEpSdna0mTZroyy+/1K+//qp9+/bpo48+UmRkpAv3zjkKOzav5+LFi7b1Wl9nz54tcJk+ffpo6tSpRfr5Yc5gGIZD36WkpDj84z63Z599Vp6ennZj1+Vcdt8erisuLs6QZHsVL17caNy4sfHFF19cd9mdO3casbGxRkhIiOHl5WXce++9xqBBg4z09HS7dnk9csAwDCMmJsZo3bq17X12drYxZcoUo2nTpkZAQIDh7e1tVKtWzejWrZuxd+/em97X2+V6t84ahmGkp6cbAwcONKpXr254eXkZISEhRmxsrLFr1y67dnk9csAwrj6iwcfHxzhy5Iht2tatW40OHToYZcuWNYoVK2aUKlXKiImJMebPn19kHzlwo2PTelt3Xq+jR48ahmEYa9euNWJiYoygoCDD29vbqFOnjvGf//zHuHLlisP6EhMTjZiYGKNkyZKGr6+vUatWLeOtt94yjh8/fsv2+1Yzc2t3Xv03YsQIwzAM4/Tp00bv3r2NsLAww8vLywgNDTU6d+5s/PHHHw7rOn78uNGzZ0+jcuXKhre3t1GxYkXjySefNH744YdbtHe3x82Mzbweh2GVX9/HxMTY2uiaRw4YxtVHitSqVcvo0aPHze6ay9zMozAM4+ojB/L72bc+IiO/bYwaNcooU6ZMno/HcAWLYdwFVwUCAADcJE7PAQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAFAAWbNmuWU7yKzWCz65ptvbno9AFyH0ATgjte5c2e1b9/e1WUAKOIITQAAACYQmgDc1caOHau6desqICBAYWFh+vvf/660tDSHdt98841q1KghX19fxcTE6OjRo3bzFy1apIYNG8rX11fVqlXTsGHDdOXKldu1GwBuA0ITgLuah4eHPvroI+3Zs0ezZ8/W6tWr1b9/f7s2Fy9e1MiRI/W///1P69ev17lz59SpUyfb/J9++kmvvPKK3nzzTe3du1dTp07VrFmzNHLkyNu9OwBuIYthGIariwCAW6lz5846d+6cqQuxv/jiC3Xv3l1//vmnpKsXgnfp0kWbNm1S06ZNJUn79+9X7dq1tXnzZjVp0kRRUVF67LHHNGDAANt65syZo/79++v48eOSrl4I/vXXX3NtFVCEFXN1AQDgSitXrtSoUaO0f/9+paam6sqVK7p8+bIuXrwof39/SVKxYsXUuHFj2zK1atVSiRIltG/fPjVp0kQ7duzQ+vXr7Y4sZWdnO6wHQNFGaAJw1zp8+LCeeOIJ9ejRQyNHjlRISIjWrVunrl27KjMz03TYSUtL07Bhw/TMM884zPP19XV22QBchNAE4K6VlJSknJwcjRkzRh4eVy/x/Pzzzx3aXblyRdu2bVOTJk0kSQcOHNC5c+dUu3ZtSVLDhg114MABVa9e/fYVD+C2IzQBuCucP39eycnJdtNKly6trKwsTZw4Ue3atdP69es1ZcoUh2W9vLzUu3dvffTRRypWrJh69eqlZs2a2ULU4MGD9cQTT+iee+5Rhw4d5OHhoR07dmj37t167733bsfuAbgNuHsOwF1hzZo1euCBB+xen376qcaOHasPPvhA999/v+bOnatRo0Y5LOvv76+3335bL7zwgh588EEFBgZqwYIFtvkxMTFavHixVqxYocaNG6tZs2YaN26cKleufDt3EcAtxt1zAAAAJnCkCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAm/D9EFe/oYN2gWgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=[k for k in tag_counts.keys() if k != 'O'], y=[v for k,v in tag_counts.items() if k != 'O'])\n",
    "plt.title(\"WikiANN NER Label Distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6079f6dd-1f5b-4343-8418-a25d2fc65c2f",
   "metadata": {},
   "source": [
    "Biggest amount of the NER tags belons to continuation of Organization Names, theyhave more ite,s compared to continuations od person and location names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4425d-a0aa-4ddd-a6d7-37ff61e1cec9",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75d91a01-452e-422d-b92b-e4be507f03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d06be21-0d81-4cdf-b311-64354571f87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original tokens (train, index 3648):\n",
      "['The', 'Pavilion', '(', 'UC', 'Davis', ')']\n",
      "Tokenized input_ids: [101, 1109, 16790, 113, 16991, 3635, 114, 102]\n",
      "Tokenized tokens: ['[CLS]', 'The', 'Pavilion', '(', 'UC', 'Davis', ')', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "split = random.choice(list(wikiann.keys()))\n",
    "ds_s = wikiann[split]\n",
    "sample_idx = random.choice(range(len(ds_s)))\n",
    "tokens = ds_s[sample_idx][\"tokens\"]\n",
    "\n",
    "print(f\"\\nOriginal tokens ({split}, index {sample_idx}):\")\n",
    "print(tokens)\n",
    "\n",
    "tokenized = tokenizer(tokens, is_split_into_words=True)\n",
    "print(\"Tokenized input_ids:\", tokenized[\"input_ids\"])\n",
    "print(\"Tokenized tokens:\", tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e684208-87b8-4260-a1f5-6c490035006b",
   "metadata": {},
   "source": [
    "We can see WikiAnn original tokens first as Id's in Bert's vocabulary and then as \"tokenized tokens\" - with Bert tokenization.\n",
    "\n",
    "Bert has:\n",
    "* [CLS] - a special token at the beginning of every sequence\n",
    "* [SEP] - a sequence boundary token marking the end of the sentence\n",
    "\n",
    "but also Bert splits wrokwns differently, for example:\n",
    "* \"'\", \"''\" turns into \"'\", \"'\", \"'\" cause Bert splits sign \"'\" from \"' '\" into 2 separate tokens\n",
    "* and 'Roff' is split to 'R' and '##off' cause it knows this suffix \"off\" and sees it as continuation of previous word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12375c-859b-4ee8-9873-de91971024c0",
   "metadata": {},
   "source": [
    "These labels are not aligned properly to the tokenized input now.\n",
    "\n",
    "\n",
    "According to HuggingFace Token Classification tutorial:\n",
    "*“Only the first token of each word should receive a label.\n",
    "All other subtokens must receive the label -100 so they are ignored during loss computation.”*\n",
    "\n",
    "So let's create a function to align them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb87a2af-1213-43bf-81bb-2115c46399f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(examples, word_list: bool = False):\n",
    "    \"\"\"\n",
    "    Align word-level NER labels with subword tokens produced by the tokenizer.\n",
    "    \n",
    "    Strategy:\n",
    "    - Assign the entity label only to the first subtoken of each word.\n",
    "    - Assign -100 to:\n",
    "        * All inner subtokens,\n",
    "        * Special tokens ([CLS], [SEP], [PAD], etc.).\n",
    "    - This ensures that the loss is computed only on first subtokens.\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    labels = []\n",
    "    word_ids_list = []\n",
    "    for i, word_labels in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        word_ids_list.append(word_ids)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(word_labels[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    if word_list:\n",
    "        tokenized_inputs[\"word_ids\"] = word_ids_list\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30375a95-989e-45ad-93a9-9a72f230b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and aligning labels for split: validation\n",
      "Tokenizing and aligning labels for split: test\n",
      "Tokenizing and aligning labels for split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████| 20000/20000 [00:04<00:00, 4401.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_wikiann = {}\n",
    "\n",
    "for split in list(wikiann.keys()):\n",
    "    print(f\"Tokenizing and aligning labels for split: {split}\")\n",
    "    tokenized_wikiann[split] = wikiann[split].map(\n",
    "        align_labels_with_tokens,\n",
    "        batched=True,\n",
    "        remove_columns=wikiann[split].column_names,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627952ae-ddc5-4cae-8bd8-7b2f495a0a2d",
   "metadata": {},
   "source": [
    "### Pretrained NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cb21ac7-9181-461a-8962-963186d72930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
      ")\n",
      "\n",
      "Number of labels in model: 9\n",
      "Model id2label: {0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC'}\n",
      "Model label2id: {'B-LOC': 7, 'B-MISC': 1, 'B-ORG': 5, 'B-PER': 3, 'I-LOC': 8, 'I-MISC': 2, 'I-ORG': 6, 'I-PER': 4, 'O': 0}\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(\"\\nNumber of labels in model:\", model.num_labels)\n",
    "print(\"Model id2label:\", model.config.id2label)\n",
    "print(\"Model label2id:\", model.config.label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323d39e-3f63-45e3-a098-c1e6bce8cbe6",
   "metadata": {},
   "source": [
    "We see a new entity - MISC – miscellaneous, for entities that don’t fit into PER/ORG/LOC like nationalities, events, products, works of art, etc. But there is no MISC class in WikiANN.\n",
    "But even though the pretrained model was trained on CoNLL-2003, it still recognizes PER / ORG / LOC correctly when you run it directly on WikiANN before fine-tuning. lets check it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90583746-fd60-4d1b-8ef6-c2a86d06ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_predictions(model, row: int, split: str = \"test\", print_res: bool = False, to_device: bool = False):\n",
    "    input_ids = tokenized_wikiann[split][row][\"input_ids\"]\n",
    "    attention_mask = tokenized_wikiann[split][row][\"attention_mask\"]\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids])\n",
    "    attention_mask_tensor = torch.tensor([attention_mask])\n",
    "\n",
    "    if to_device:\n",
    "        model_device = next(model.parameters()).device\n",
    "        input_ids_tensor = input_ids_tensor.to(model_device)\n",
    "        attention_mask_tensor = attention_mask_tensor.to(model_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    id2label = model.config.id2label\n",
    "    predicted_labels = [id2label[idx.item()] for idx in predictions[0]]\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    if print_res:\n",
    "        print(f\"\\nExample row {row} from split '{split}':\")\n",
    "        for token, label in zip(tokens, predicted_labels):\n",
    "            if \"[PAD]\" not in token:\n",
    "                print(f\"{token:15} -> {label}\")\n",
    "\n",
    "    return predicted_labels, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "857b2d2b-8e1b-4be0-9a15-f63ad48f2d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example row 409 from split 'test':\n",
      "[CLS]           -> O\n",
      "'               -> O\n",
      "'               -> O\n",
      "'               -> O\n",
      "Shan            -> B-PER\n",
      "##i             -> B-PER\n",
      "Davis           -> I-PER\n",
      "'               -> O\n",
      "'               -> O\n",
      "'               -> O\n",
      "[SEP]           -> O\n"
     ]
    }
   ],
   "source": [
    "random_row = random.choice(range(len(tokenized_wikiann[\"test\"])))\n",
    "row_labels, row_tokens = check_predictions(model, random_row, print_res=True, split=\"test\", to_device=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8e3a5-0f17-4009-9602-8b6105c1ec91",
   "metadata": {},
   "source": [
    "The model correctly identified \"Charlie Smith\" as a PERSON entity cause it knows what a person is, but it also added label B-MISC for word \"Romani\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c803c13-81c5-48c7-a476-0710218cb562",
   "metadata": {},
   "source": [
    "### Initial finetuning \n",
    "we want to adapt the pretrained CoNLL NER model to the WikiANN dataset so it can recognize entities according to WikiANN’s style, vocabulary, and annotation rules. The MISC mismatch makes the fine-tuned model sometimes perform worse than the pretrained one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "249b5672-48e2-419f-a6b0-33a6cf80ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10024/2636110953.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-wikiann-bert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3, \n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "label_names = wikiann[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_wikiann[\"train\"],\n",
    "    eval_dataset=tokenized_wikiann[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a36b399-ec30-495a-8be1-1eb882547a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 11:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.242228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.272253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.318540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=7500, training_loss=0.16883512010574342, metrics={'train_runtime': 694.3901, 'train_samples_per_second': 86.407, 'train_steps_per_second': 10.801, 'total_flos': 1.57310602573824e+16, 'train_loss': 0.16883512010574342, 'epoch': 3.0})\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "print(train_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba9721a0-1d92-46ea-93ff-b5ad756c0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = trainer.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874affc6-52b4-4ae2-b023-c50bfc33f53d",
   "metadata": {},
   "source": [
    "Let's compare before and after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d569f5c1-df23-4a1a-bd92-f05dbccbe9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_before_and_after(model_1, model_2, num_examples_to_check = 100):\n",
    "    random_rows = [random.choice(range(len(tokenized_wikiann[\"test\"]))) for _ in range(num_examples_to_check)]\n",
    "    before_tokens = []\n",
    "    before_labels = []\n",
    "    after_tokens = []\n",
    "    after_labels = []\n",
    "    \n",
    "    for idx, row in enumerate(random_rows):\n",
    "        old_labels, old_tokens = check_predictions(\n",
    "            model_1,\n",
    "            row,\n",
    "            split=\"test\",\n",
    "            to_device=True\n",
    "        )\n",
    "    \n",
    "        new_labels, new_tokens = check_predictions(\n",
    "            model_2,\n",
    "            row,\n",
    "            split=\"test\",\n",
    "            to_device=True\n",
    "        )\n",
    "    \n",
    "        before_tokens.append(old_tokens)\n",
    "        before_labels.append(old_labels)\n",
    "    \n",
    "        after_tokens.append(new_tokens)\n",
    "        after_labels.append(new_labels)\n",
    "        \n",
    "    for i, row in enumerate(random_rows):\n",
    "        old_toks = before_tokens[i]\n",
    "        new_toks = after_tokens[i]\n",
    "        old_labs = before_labels[i]\n",
    "        new_labs = after_labels[i]\n",
    "    \n",
    "        changes = []\n",
    "    \n",
    "        for tok, old_lab, new_lab in zip(old_toks, old_labs, new_labs):\n",
    "            if tok.startswith(\"[PAD]\"):\n",
    "                continue\n",
    "            if old_lab != new_lab:\n",
    "                changes.append((tok, old_lab, new_lab))\n",
    "    \n",
    "        if changes:\n",
    "            print(f\"\\nChanges for example row {row}:\")\n",
    "            print(f\"{'Token':15} {'OLD label':12} {'NEW label'}\")\n",
    "            for tok, old_lab, new_lab in changes:\n",
    "                print(f\"{tok:15} {old_lab:12} {new_lab}\")\n",
    "    return changes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16d8e7ac-f4c4-4247-b317-71d9b1d5f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = compare_before_and_after(model, fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b11f0c8c-4593-472c-95c3-3c68795b9bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956a627-d159-44c9-a98c-c1d3fe0588e6",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Even though the model was fine-tuned on WikiANN, its predictions did not change compared to the pretrained model. This happens because the pretrained model was trained on CoNLL-2003 and expects four entity types (PER, ORG, LOC, MISC), while WikiANN provides only three and never contains MISC. As a result, the classifier head keeps its original MISC logits, receives no supervision for this label, and cannot fully adjust to the WikiANN label space. Therefore, fine-tuning updates the weights slightly but does not meaningfully alter the model’s predictions.\n",
    "\n",
    "It means that we gotta change our approach. Let's reinitialize classifier with base Bert and make labels match Wikipedia Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf20d50-7a09-4404-abe2-ce6feebf06b4",
   "metadata": {},
   "source": [
    "### Adapting finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9d8cb78-834c-4612-b35a-3835e0bfb089",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = wikiann[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04d7d95b-1219-49e7-94a1-7f56124e8398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_bert = \"bert-base-cased\"\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    base_bert,\n",
    "    num_labels=len(label_list)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc41c3e3-3904-49ba-a7a7-2f340bf56896",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.id2label = {i: label for i, label in enumerate(label_list)}\n",
    "base_model.config.label2id = {label: i for i, label in enumerate(label_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "528ba5d1-01c8-4fb6-b7fb-964a8aa56f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10024/2076024500.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-wikiann-basebert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5, \n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "label_names = wikiann[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_wikiann[\"train\"],\n",
    "    eval_dataset=tokenized_wikiann[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ed54d1c-ac60-4f2f-a2fa-4abd115843fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 19:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.248796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.268698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.305117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.357116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.393440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=12500, training_loss=0.15951588114261628, metrics={'train_runtime': 1141.3463, 'train_samples_per_second': 87.616, 'train_steps_per_second': 10.952, 'total_flos': 2.61308568576e+16, 'train_loss': 0.15951588114261628, 'epoch': 5.0})\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "print(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93b70223-82d2-4000-ba23-97caa86bebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_base_model = trainer.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "539c632d-59b6-42db-b8d5-5d21c127a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Changes for example row 1679:\n",
      "Token           OLD label    NEW label\n",
      "R               B-MISC       B-PER\n",
      "##ón            B-MISC       B-PER\n",
      "##ald           B-MISC       B-PER\n",
      "González        I-MISC       I-PER\n",
      "B               I-MISC       I-PER\n",
      "##rene          I-MISC       I-PER\n",
      "##s             I-MISC       I-PER\n",
      "Costa           B-ORG        B-LOC\n",
      "Rica            I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 8935:\n",
      "Token           OLD label    NEW label\n",
      "Cook            B-PER        B-ORG\n",
      "P               I-MISC       I-ORG\n",
      "##VI            I-PER        I-ORG\n",
      "R               O            B-ORG\n",
      "+               O            I-ORG\n",
      "\n",
      "Changes for example row 1424:\n",
      "Token           OLD label    NEW label\n",
      "Franz           B-ORG        B-LOC\n",
      "Josef           I-ORG        I-LOC\n",
      "Land            I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 9674:\n",
      "Token           OLD label    NEW label\n",
      "[CLS]           O            I-LOC\n",
      "Z               B-ORG        B-LOC\n",
      "##am            I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Hu              I-ORG        I-LOC\n",
      "##ned           I-ORG        I-LOC\n",
      "##oar           I-ORG        I-LOC\n",
      "##a             I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 6912:\n",
      "Token           OLD label    NEW label\n",
      "Cha             B-MISC       B-PER\n",
      "##lmer          I-MISC       I-PER\n",
      "##s             I-MISC       I-PER\n",
      ",               I-MISC       I-PER\n",
      "David           I-MISC       I-PER\n",
      "[SEP]           I-MISC       O\n",
      "\n",
      "Changes for example row 520:\n",
      "Token           OLD label    NEW label\n",
      "Charlie         B-MISC       B-PER\n",
      "Smith           I-MISC       I-PER\n",
      "(               I-MISC       I-PER\n",
      "Romani          I-MISC       I-PER\n",
      "poet            I-MISC       I-PER\n",
      ")               I-MISC       I-PER\n",
      "[SEP]           I-MISC       O\n",
      "\n",
      "Changes for example row 488:\n",
      "Token           OLD label    NEW label\n",
      "Simon           B-MISC       B-PER\n",
      "Johannes        I-MISC       I-PER\n",
      "van             I-MISC       I-PER\n",
      "Do              I-MISC       I-PER\n",
      "##u             I-MISC       I-PER\n",
      "##w             I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 1535:\n",
      "Token           OLD label    NEW label\n",
      "Music           B-PER        B-ORG\n",
      "Corporation     I-PER        I-ORG\n",
      "of              I-PER        I-ORG\n",
      "America         I-PER        I-ORG\n",
      "\n",
      "Changes for example row 3582:\n",
      "Token           OLD label    NEW label\n",
      "Darling         B-ORG        B-LOC\n",
      "##hurst         I-ORG        I-LOC\n",
      "/               O            I-LOC\n",
      "East            B-ORG        B-LOC\n",
      "Sydney          I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 3811:\n",
      "Token           OLD label    NEW label\n",
      "Second          B-PER        B-ORG\n",
      "Division        I-PER        I-ORG\n",
      "Port            B-PER        B-ORG\n",
      "Vale            I-PER        I-ORG\n",
      "\n",
      "Changes for example row 8279:\n",
      "Token           OLD label    NEW label\n",
      "Ch              B-PER        B-ORG\n",
      "##est           I-PER        I-ORG\n",
      "##nut           I-PER        I-ORG\n",
      ":               I-PER        I-ORG\n",
      "Hero            I-PER        I-ORG\n",
      "of              I-PER        I-ORG\n",
      "Central         I-PER        I-ORG\n",
      "Park            I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 9863:\n",
      "Token           OLD label    NEW label\n",
      "'               O            B-ORG\n",
      "92              B-PER        B-ORG\n",
      "##3             I-PER        I-ORG\n",
      "in              I-PER        I-ORG\n",
      "poetry          I-PER        I-ORG\n",
      "\n",
      "Changes for example row 434:\n",
      "Token           OLD label    NEW label\n",
      "Les             B-PER        B-ORG\n",
      "con             I-PER        I-ORG\n",
      "##tes           I-PER        I-ORG\n",
      "d               I-PER        I-ORG\n",
      "'               I-PER        I-ORG\n",
      "Hoffmann        I-PER        I-ORG\n",
      "\n",
      "Changes for example row 9195:\n",
      "Token           OLD label    NEW label\n",
      "Pan             B-ORG        B-LOC\n",
      "##to            I-PER        I-LOC\n",
      "##les           I-PER        I-LOC\n",
      "##ti            I-PER        I-LOC\n",
      "##dae           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 3257:\n",
      "Token           OLD label    NEW label\n",
      "Princess        B-MISC       B-PER\n",
      "Maria           I-MISC       I-PER\n",
      "Carolina        I-MISC       I-PER\n",
      "of              I-MISC       I-PER\n",
      "Bourbon         I-MISC       I-PER\n",
      "-               I-MISC       I-PER\n",
      "Two             I-MISC       I-PER\n",
      "Si              I-MISC       I-PER\n",
      "##ci            I-MISC       I-PER\n",
      "##lies          I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 8928:\n",
      "Token           OLD label    NEW label\n",
      "Russian         B-ORG        B-LOC\n",
      "Empire          I-ORG        I-LOC\n",
      "Soviet          B-ORG        B-LOC\n",
      "Union           I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 6873:\n",
      "Token           OLD label    NEW label\n",
      "[CLS]           I-ORG        I-LOC\n",
      "B               B-ORG        B-LOC\n",
      "##r             I-ORG        I-LOC\n",
      "##ă             I-ORG        I-LOC\n",
      "##det           I-ORG        I-LOC\n",
      "##ul            I-ORG        I-LOC\n",
      "River           I-ORG        I-LOC\n",
      "(               I-ORG        I-LOC\n",
      "T               I-ORG        I-LOC\n",
      "##ă             I-ORG        I-LOC\n",
      "##lm            I-ORG        I-LOC\n",
      "##ă             I-ORG        I-LOC\n",
      "##cu            I-ORG        I-LOC\n",
      "##ț             I-ORG        I-LOC\n",
      "##a             I-ORG        I-LOC\n",
      ")               I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 3611:\n",
      "Token           OLD label    NEW label\n",
      "Di              B-ORG        B-LOC\n",
      "##cho           I-ORG        I-LOC\n",
      "##mer           I-ORG        I-LOC\n",
      "##is            I-ORG        I-LOC\n",
      "a               I-ORG        I-LOC\n",
      "##cum           I-ORG        I-LOC\n",
      "##ina           I-ORG        I-LOC\n",
      "##ta            I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 7359:\n",
      "Token           OLD label    NEW label\n",
      "Gas             B-ORG        B-LOC\n",
      "City            I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Indiana         I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 9654:\n",
      "Token           OLD label    NEW label\n",
      "April           B-PER        B-ORG\n",
      "##ia            I-PER        I-ORG\n",
      "\n",
      "Changes for example row 4557:\n",
      "Token           OLD label    NEW label\n",
      "Charles         B-MISC       B-PER\n",
      "-               I-MISC       I-PER\n",
      "Louis           I-MISC       I-PER\n",
      "Co              I-MISC       I-PER\n",
      "##rb            I-MISC       I-PER\n",
      "##et            I-MISC       I-PER\n",
      "\n",
      "Changes for example row 106:\n",
      "Token           OLD label    NEW label\n",
      "Martín          B-MISC       B-PER\n",
      "de              I-MISC       I-PER\n",
      "U               I-MISC       I-PER\n",
      "##rs            I-MISC       I-PER\n",
      "##ú             I-MISC       I-PER\n",
      "##a             I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 2615:\n",
      "Token           OLD label    NEW label\n",
      "Omega           B-PER        B-ORG\n",
      "Mission         I-PER        I-ORG\n",
      "Hills           I-PER        I-ORG\n",
      "World           I-PER        I-ORG\n",
      "Cup             I-PER        I-ORG\n",
      "Matt            B-MISC       B-PER\n",
      "Ku              I-MISC       I-PER\n",
      "##cha           I-MISC       I-PER\n",
      "##r             I-MISC       I-PER\n",
      "\n",
      "Changes for example row 6924:\n",
      "Token           OLD label    NEW label\n",
      "Institute       B-PER        B-ORG\n",
      "of              I-PER        I-ORG\n",
      "Na              I-PER        I-ORG\n",
      "##utical        I-PER        I-ORG\n",
      "Archaeology     I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 5574:\n",
      "Token           OLD label    NEW label\n",
      "Bulgaria        B-ORG        B-LOC\n",
      "Soviet          B-ORG        B-LOC\n",
      "Union           I-ORG        I-LOC\n",
      "Hungary         B-ORG        B-LOC\n",
      "Czechoslovakia  B-ORG        B-LOC\n",
      "Romania         B-ORG        B-LOC\n",
      "East            B-ORG        B-LOC\n",
      "Germany         I-ORG        I-LOC\n",
      "West            B-ORG        B-LOC\n",
      "Germany         I-ORG        I-LOC\n",
      "Cuba            B-ORG        B-LOC\n",
      "Poland          B-ORG        B-LOC\n",
      "North           B-ORG        B-LOC\n",
      "Korea           I-ORG        I-LOC\n",
      "Yugoslavia      B-ORG        B-LOC\n",
      "Sweden          B-ORG        B-LOC\n",
      "Denmark         B-ORG        B-LOC\n",
      "France          B-ORG        B-LOC\n",
      "Belgium         B-ORG        B-LOC\n",
      "Netherlands     B-ORG        B-LOC\n",
      "Italy           B-ORG        B-LOC\n",
      "Japan           B-ORG        B-LOC\n",
      "\n",
      "Changes for example row 4552:\n",
      "Token           OLD label    NEW label\n",
      "Diocese         B-ORG        B-LOC\n",
      "of              I-ORG        I-LOC\n",
      "S               I-ORG        I-LOC\n",
      "##yr            I-ORG        I-LOC\n",
      "##os            I-ORG        I-LOC\n",
      "and             I-ORG        I-LOC\n",
      "Milo            I-ORG        I-LOC\n",
      "##s             I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 2547:\n",
      "Token           OLD label    NEW label\n",
      "Jorge           B-MISC       B-PER\n",
      "So              I-MISC       I-PER\n",
      "##sa            I-MISC       I-PER\n",
      "\n",
      "Changes for example row 3527:\n",
      "Token           OLD label    NEW label\n",
      "Pavel           B-PER        B-LOC\n",
      "##l             I-PER        I-LOC\n",
      "##ó             I-PER        I-LOC\n",
      "del             I-PER        I-LOC\n",
      "Club            I-PER        I-LOC\n",
      "Pat             I-PER        I-LOC\n",
      "##í             I-PER        I-LOC\n",
      "Vic             I-PER        I-LOC\n",
      "[SEP]           I-PER        I-LOC\n",
      "\n",
      "Changes for example row 5514:\n",
      "Token           OLD label    NEW label\n",
      "Brazil          B-ORG        B-LOC\n",
      "French          B-ORG        B-LOC\n",
      "Guiana          I-ORG        I-LOC\n",
      "Guyana          B-ORG        B-LOC\n",
      "Sur             B-ORG        B-LOC\n",
      "##iname         I-ORG        I-LOC\n",
      "Venezuela       B-ORG        B-LOC\n",
      "\n",
      "Changes for example row 1674:\n",
      "Token           OLD label    NEW label\n",
      "Empire          B-ORG        B-LOC\n",
      "of              I-ORG        I-LOC\n",
      "Japan           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 1519:\n",
      "Token           OLD label    NEW label\n",
      "University      B-PER        B-ORG\n",
      "of              I-PER        I-ORG\n",
      "Technology      I-PER        I-ORG\n",
      "of              I-PER        I-ORG\n",
      "Co              I-PER        I-ORG\n",
      "##mp            I-PER        I-ORG\n",
      "##i             I-PER        I-ORG\n",
      "##è             I-PER        I-ORG\n",
      "##gne           I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 6224:\n",
      "Token           OLD label    NEW label\n",
      "Sri             B-ORG        B-LOC\n",
      "Lanka           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 1584:\n",
      "Token           OLD label    NEW label\n",
      "N               B-PER        B-ORG\n",
      "##K             I-PER        I-ORG\n",
      "##VD            I-PER        I-ORG\n",
      "Order           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 5881:\n",
      "Token           OLD label    NEW label\n",
      "[CLS]           O            I-LOC\n",
      "A               B-MISC       B-LOC\n",
      "##bid           B-ORG        I-LOC\n",
      "Ali             I-ORG        I-LOC\n",
      "Nazis           I-ORG        I-LOC\n",
      "##h             I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 5635:\n",
      "Token           OLD label    NEW label\n",
      "Washington      B-PER        B-ORG\n",
      "Arlington       B-PER        B-ORG\n",
      "Alexandria      B-PER        B-ORG\n",
      ",               I-PER        I-ORG\n",
      "DC              I-PER        I-ORG\n",
      "VA              B-PER        B-ORG\n",
      "MD              B-PER        B-ORG\n",
      "W               B-PER        I-ORG\n",
      "##V             I-PER        I-ORG\n",
      "MS              I-PER        I-ORG\n",
      "##A             I-PER        I-ORG\n",
      "\n",
      "Changes for example row 9891:\n",
      "Token           OLD label    NEW label\n",
      "William         B-MISC       B-PER\n",
      "C               I-MISC       I-PER\n",
      "##abe           I-MISC       I-PER\n",
      "##ll            I-MISC       I-PER\n",
      "R               I-MISC       I-PER\n",
      "##ives          I-MISC       I-PER\n",
      "\n",
      "Changes for example row 4333:\n",
      "Token           OLD label    NEW label\n",
      "American        B-PER        B-ORG\n",
      "Juniors         I-PER        I-ORG\n",
      "\n",
      "Changes for example row 711:\n",
      "Token           OLD label    NEW label\n",
      "Kelly           B-MISC       B-PER\n",
      "Moore           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 7527:\n",
      "Token           OLD label    NEW label\n",
      "India           B-ORG        B-LOC\n",
      "Thailand        B-ORG        B-LOC\n",
      "Laos            B-ORG        B-LOC\n",
      "Burma           B-ORG        B-LOC\n",
      "Malaya          I-ORG        I-LOC\n",
      "Java            B-ORG        B-LOC\n",
      "Sumatra         B-ORG        B-LOC\n",
      "Borneo          B-ORG        B-LOC\n",
      "\n",
      "Changes for example row 8785:\n",
      "Token           OLD label    NEW label\n",
      "W               B-ORG        B-LOC\n",
      "##il            B-ORG        I-LOC\n",
      "##by            I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Suffolk         I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 2045:\n",
      "Token           OLD label    NEW label\n",
      "126             B-PER        B-ORG\n",
      "##th            I-PER        I-ORG\n",
      "Air             I-PER        I-ORG\n",
      "Re              I-PER        I-ORG\n",
      "##fueling       I-PER        I-ORG\n",
      "Wing            I-PER        I-ORG\n",
      "Scott           B-PER        B-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 6201:\n",
      "Token           OLD label    NEW label\n",
      "Stan            B-MISC       B-PER\n",
      "##yar           I-MISC       I-PER\n",
      "##ne            I-MISC       I-PER\n",
      "Wilson          I-MISC       I-PER\n",
      "\n",
      "Changes for example row 1291:\n",
      "Token           OLD label    NEW label\n",
      "Institut        B-PER        B-ORG\n",
      "des             I-PER        I-ORG\n",
      "Sciences        I-PER        I-ORG\n",
      "Pol             I-PER        I-ORG\n",
      "##iti           I-PER        I-ORG\n",
      "##ques          I-PER        I-ORG\n",
      "Humboldt        B-PER        B-ORG\n",
      "University      I-PER        I-ORG\n",
      "\n",
      "Changes for example row 4803:\n",
      "Token           OLD label    NEW label\n",
      "Moses           B-MISC       B-PER\n",
      "III             I-MISC       I-PER\n",
      "of              I-MISC       I-PER\n",
      "Armenia         I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 5925:\n",
      "Token           OLD label    NEW label\n",
      "Ham             B-PER        B-ORG\n",
      "##mad           I-PER        I-ORG\n",
      "##ids           I-PER        I-ORG\n",
      "Ham             B-MISC       B-PER\n",
      "##mad           I-MISC       I-PER\n",
      "ibn             I-MISC       I-PER\n",
      "B               I-MISC       I-PER\n",
      "##ulu           I-MISC       I-PER\n",
      "##gg            I-MISC       I-PER\n",
      "##in            I-MISC       I-PER\n",
      "\n",
      "Changes for example row 9459:\n",
      "Token           OLD label    NEW label\n",
      "Sc              B-ORG        B-LOC\n",
      "##hen           I-ORG        I-LOC\n",
      "##ec            I-ORG        I-LOC\n",
      "##tad           I-ORG        I-LOC\n",
      "##y             I-ORG        I-LOC\n",
      "County          I-ORG        I-LOC\n",
      "[SEP]           I-ORG        O\n",
      "\n",
      "Changes for example row 3150:\n",
      "Token           OLD label    NEW label\n",
      "Most            I-PER        I-ORG\n",
      "Council         I-PER        I-ORG\n",
      "[SEP]           I-PER        O\n",
      "\n",
      "Changes for example row 1139:\n",
      "Token           OLD label    NEW label\n",
      "Simon           B-PER        B-ORG\n",
      "&               I-PER        I-ORG\n",
      "Schuster        I-PER        I-ORG\n",
      "\n",
      "Changes for example row 750:\n",
      "Token           OLD label    NEW label\n",
      "Lillian         B-MISC       B-PER\n",
      "G               I-MISC       I-PER\n",
      "##ish           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 3733:\n",
      "Token           OLD label    NEW label\n",
      "Bob             B-MISC       B-PER\n",
      "Kane            I-MISC       I-PER\n",
      "Batman          B-MISC       B-PER\n",
      "Gotham          B-PER        B-LOC\n",
      "City            I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 4741:\n",
      "Token           OLD label    NEW label\n",
      "Edmonton        B-PER        B-ORG\n",
      "E               I-PER        I-ORG\n",
      "##ski           I-PER        I-ORG\n",
      "##mos           I-PER        I-ORG\n",
      "Western         B-PER        B-ORG\n",
      "Canada          I-PER        I-ORG\n",
      "League          I-PER        I-ORG\n",
      "\n",
      "Changes for example row 1307:\n",
      "Token           OLD label    NEW label\n",
      "Richmond        B-ORG        B-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Virginia        I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 3814:\n",
      "Token           OLD label    NEW label\n",
      "[CLS]           O            I-LOC\n",
      "Co              B-ORG        B-LOC\n",
      "##rb            I-ORG        I-LOC\n",
      "##u             I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Ha              I-ORG        I-LOC\n",
      "##rg            I-ORG        I-LOC\n",
      "##hita          I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 1654:\n",
      "Token           OLD label    NEW label\n",
      "Ta              B-ORG        B-PER\n",
      "##y             I-ORG        I-PER\n",
      "##pi            I-ORG        I-PER\n",
      "Cha             I-ORG        I-PER\n",
      "##ka            I-ORG        I-PER\n",
      "Q               I-ORG        I-PER\n",
      "##uta           I-ORG        I-PER\n",
      "[SEP]           I-ORG        I-PER\n",
      "\n",
      "Changes for example row 6227:\n",
      "Token           OLD label    NEW label\n",
      "South           B-ORG        B-LOC\n",
      "Korea           I-ORG        I-LOC\n",
      "China           B-ORG        B-LOC\n",
      "\n",
      "Changes for example row 4554:\n",
      "Token           OLD label    NEW label\n",
      "Tri             B-ORG        B-LOC\n",
      "##cho           I-ORG        I-LOC\n",
      "##dez           I-ORG        I-LOC\n",
      "##ia            I-ORG        I-LOC\n",
      "al              I-ORG        I-LOC\n",
      "##bo            I-ORG        I-LOC\n",
      "##fa            I-ORG        I-LOC\n",
      "##s             I-ORG        I-LOC\n",
      "##cia           I-ORG        I-LOC\n",
      "##ta            I-ORG        I-LOC\n",
      "[SEP]           I-ORG        O\n",
      "\n",
      "Changes for example row 7428:\n",
      "Token           OLD label    NEW label\n",
      "Albuquerque     B-PER        B-ORG\n",
      "Metropolitan    I-PER        I-ORG\n",
      "Statistical     I-PER        I-ORG\n",
      "Area            I-PER        I-ORG\n",
      "\n",
      "Changes for example row 5977:\n",
      "Token           OLD label    NEW label\n",
      "A               B-ORG        B-LOC\n",
      "##pa            I-ORG        I-LOC\n",
      "##me            I-ORG        I-LOC\n",
      "##a             I-ORG        I-LOC\n",
      "un              I-ORG        I-LOC\n",
      "##ani           I-ORG        I-LOC\n",
      "##mis           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 2664:\n",
      "Token           OLD label    NEW label\n",
      "Indiana         B-PER        B-ORG\n",
      "State           I-PER        I-ORG\n",
      "Road            I-PER        I-ORG\n",
      "117             I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 6065:\n",
      "Token           OLD label    NEW label\n",
      "Kingdom         B-ORG        B-LOC\n",
      "of              I-ORG        I-LOC\n",
      "North           I-ORG        I-LOC\n",
      "##umbria        I-ORG        I-LOC\n",
      "Æ               B-MISC       B-PER\n",
      "##lla           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 5820:\n",
      "Token           OLD label    NEW label\n",
      "'               B-PER        B-ORG\n",
      "'               B-PER        B-ORG\n",
      "Believe         B-PER        B-ORG\n",
      "in              I-PER        I-ORG\n",
      "Me              I-PER        I-ORG\n",
      "'               I-PER        I-ORG\n",
      "'               I-PER        I-ORG\n",
      "(               I-PER        I-ORG\n",
      "Duff            I-PER        I-ORG\n",
      "M               I-PER        I-ORG\n",
      "##c             I-PER        I-ORG\n",
      "##K             I-PER        I-ORG\n",
      "##agan          I-PER        I-ORG\n",
      "album           I-PER        I-ORG\n",
      ")               I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 3432:\n",
      "Token           OLD label    NEW label\n",
      "Department      B-PER        B-ORG\n",
      "of              I-PER        I-ORG\n",
      "Health          I-PER        I-ORG\n",
      "and             I-PER        I-ORG\n",
      "Human           I-PER        I-ORG\n",
      "Services        I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 4374:\n",
      "Token           OLD label    NEW label\n",
      "The             B-PER        B-ORG\n",
      "C               I-PER        I-ORG\n",
      "##lash          I-PER        I-ORG\n",
      "of              I-PER        I-ORG\n",
      "Tri             I-PER        I-ORG\n",
      "##ton           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 1169:\n",
      "Token           OLD label    NEW label\n",
      "'               B-PER        O\n",
      "Law             B-PER        B-ORG\n",
      "&               I-PER        I-ORG\n",
      "Order           I-PER        I-ORG\n",
      ":               I-PER        I-ORG\n",
      "UK              I-PER        I-ORG\n",
      "13th            B-PER        B-ORG\n",
      "Street          I-PER        I-ORG\n",
      "\n",
      "Changes for example row 9980:\n",
      "Token           OLD label    NEW label\n",
      "I               B-PER        B-ORG\n",
      "Do              I-PER        I-ORG\n",
      "n               I-PER        I-ORG\n",
      "'               I-PER        I-ORG\n",
      "t               I-PER        I-ORG\n",
      "Want            I-PER        I-ORG\n",
      "to              I-PER        I-ORG\n",
      "Wait            I-PER        I-ORG\n",
      "[SEP]           I-PER        O\n",
      "\n",
      "Changes for example row 2803:\n",
      "Token           OLD label    NEW label\n",
      "Pen             B-PER        B-ORG\n",
      "##t             I-PER        I-ORG\n",
      "##wyn           I-PER        I-ORG\n",
      "Dynamo          I-PER        I-ORG\n",
      "F               I-PER        I-ORG\n",
      ".               I-PER        I-ORG\n",
      "C               I-PER        I-ORG\n",
      ".               I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 8751:\n",
      "Token           OLD label    NEW label\n",
      "Tri             B-ORG        B-LOC\n",
      "##ax            I-ORG        I-LOC\n",
      "##omer          I-ORG        I-LOC\n",
      "##a             I-ORG        I-LOC\n",
      "parasite        I-ORG        I-LOC\n",
      "##lla           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 4010:\n",
      "Token           OLD label    NEW label\n",
      "Ray             B-ORG        B-LOC\n",
      "##town          I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Missouri        I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 2677:\n",
      "Token           OLD label    NEW label\n",
      "Alex            B-MISC       B-PER\n",
      "Ba              I-MISC       I-PER\n",
      "##ldo           I-MISC       I-PER\n",
      "##lini          I-MISC       I-PER\n",
      "\n",
      "Changes for example row 7573:\n",
      "Token           OLD label    NEW label\n",
      "Got             B-ORG        B-LOC\n",
      "##ha            I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 6216:\n",
      "Token           OLD label    NEW label\n",
      "O               B-ORG        B-LOC\n",
      "'               I-ORG        I-LOC\n",
      "Fallon          I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "Illinois        I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 4422:\n",
      "Token           OLD label    NEW label\n",
      "Germany         B-ORG        B-LOC\n",
      "\n",
      "Changes for example row 9125:\n",
      "Token           OLD label    NEW label\n",
      "Michael         B-MISC       B-PER\n",
      "E               I-MISC       I-PER\n",
      ".               I-MISC       I-PER\n",
      "Thornton        I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 3598:\n",
      "Token           OLD label    NEW label\n",
      "Buddy           B-MISC       B-PER\n",
      "Merrill         I-MISC       I-PER\n",
      "\n",
      "Changes for example row 5313:\n",
      "Token           OLD label    NEW label\n",
      "Fr              B-PER        B-ORG\n",
      "##eak           I-PER        I-ORG\n",
      "##water         I-PER        I-ORG\n",
      "\n",
      "Changes for example row 916:\n",
      "Token           OLD label    NEW label\n",
      "##po            O            I-LOC\n",
      "##ng            I-PER        I-LOC\n",
      "##illa          I-ORG        I-LOC\n",
      "##flies         I-ORG        I-LOC\n",
      "O               B-ORG        B-LOC\n",
      "##sm            I-ORG        I-LOC\n",
      "##yl            I-ORG        I-LOC\n",
      "##oid           I-ORG        I-LOC\n",
      "##ea            I-ORG        I-LOC\n",
      "o               B-ORG        B-LOC\n",
      "##sm            I-ORG        I-LOC\n",
      "##yl            I-ORG        I-LOC\n",
      "##ids           I-ORG        I-LOC\n",
      "O               B-ORG        B-LOC\n",
      "##sm            I-ORG        I-LOC\n",
      "##yl            I-ORG        I-LOC\n",
      "##idae          I-ORG        I-LOC\n",
      "N               B-ORG        B-LOC\n",
      "##ev            B-ORG        I-LOC\n",
      "##ro            I-ORG        I-LOC\n",
      "##rth           I-ORG        I-LOC\n",
      "##idae          I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 3752:\n",
      "Token           OLD label    NEW label\n",
      "Ibn             B-MISC       B-PER\n",
      "al              I-MISC       I-PER\n",
      "-               I-MISC       O\n",
      "Mal             I-MISC       O\n",
      "##â             I-MISC       I-PER\n",
      "##him           I-MISC       I-PER\n",
      "##î             O            I-PER\n",
      "A               B-MISC       B-PER\n",
      "##b             I-MISC       I-PER\n",
      "##û             I-MISC       I-PER\n",
      "'               I-MISC       I-PER\n",
      "l               I-MISC       I-PER\n",
      "-               I-MISC       I-PER\n",
      "Hu              I-MISC       I-PER\n",
      "##say           I-MISC       I-PER\n",
      "##n             I-MISC       I-PER\n",
      "al              I-MISC       I-PER\n",
      "-               I-MISC       I-PER\n",
      "Ba              I-MISC       I-PER\n",
      "##s             I-MISC       I-PER\n",
      "##r             I-MISC       I-PER\n",
      "##î             I-MISC       I-PER\n",
      "\n",
      "Changes for example row 525:\n",
      "Token           OLD label    NEW label\n",
      "E               B-ORG        B-LOC\n",
      "##pi            B-ORG        B-LOC\n",
      "##rr            I-ORG        I-LOC\n",
      "##hoe           I-ORG        I-LOC\n",
      "m               I-ORG        I-LOC\n",
      "##oll           I-ORG        I-LOC\n",
      "##ug            I-ORG        I-LOC\n",
      "##ina           I-ORG        I-LOC\n",
      "##ta            I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 5168:\n",
      "Token           OLD label    NEW label\n",
      "Front           B-PER        B-ORG\n",
      "Line            I-PER        I-ORG\n",
      "De              I-PER        I-ORG\n",
      "##fender        I-PER        I-ORG\n",
      "##s             I-PER        I-ORG\n",
      "\n",
      "Changes for example row 6572:\n",
      "Token           OLD label    NEW label\n",
      "Unionist        B-PER        B-ORG\n",
      "##s             I-PER        O\n",
      "\n",
      "Changes for example row 4386:\n",
      "Token           OLD label    NEW label\n",
      "Master          B-PER        B-ORG\n",
      "of              I-PER        I-ORG\n",
      "Religious       I-PER        I-ORG\n",
      "Education       I-PER        I-ORG\n",
      "\n",
      "Changes for example row 1084:\n",
      "Token           OLD label    NEW label\n",
      "Kingdom         B-ORG        B-LOC\n",
      "of              I-ORG        I-LOC\n",
      "Sussex          I-ORG        I-LOC\n",
      "E               B-MISC       B-PER\n",
      "##ald           B-MISC       I-PER\n",
      "##wu            I-MISC       I-PER\n",
      "##lf            I-MISC       I-PER\n",
      "\n",
      "Changes for example row 3456:\n",
      "Token           OLD label    NEW label\n",
      "B               B-ORG        B-LOC\n",
      "##ren           B-ORG        I-LOC\n",
      "##ner           I-ORG        I-LOC\n",
      ",               I-ORG        I-LOC\n",
      "South           I-ORG        I-LOC\n",
      "Ty              I-ORG        I-LOC\n",
      "##rol           I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 9292:\n",
      "Token           OLD label    NEW label\n",
      "St              B-PER        B-LOC\n",
      "##rab           I-ORG        I-LOC\n",
      "##ane           I-ORG        I-LOC\n",
      "Ma              I-PER        I-LOC\n",
      "##st            I-PER        I-LOC\n",
      "St              B-ORG        B-LOC\n",
      "##rab           I-ORG        I-LOC\n",
      "##ane           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 5155:\n",
      "Token           OLD label    NEW label\n",
      "Afghanistan     B-ORG        B-LOC\n",
      "\n",
      "Changes for example row 3483:\n",
      "Token           OLD label    NEW label\n",
      "[CLS]           B-ORG        I-LOC\n",
      "Co              B-ORG        B-LOC\n",
      "##mm            I-ORG        I-LOC\n",
      "##une           I-ORG        I-LOC\n",
      "##s             I-ORG        I-LOC\n",
      "of              I-ORG        I-LOC\n",
      "the             I-ORG        I-LOC\n",
      "Land            I-ORG        I-LOC\n",
      "##es            I-ORG        I-LOC\n",
      "department      I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 8179:\n",
      "Token           OLD label    NEW label\n",
      "Car             B-PER        B-ORG\n",
      "##ni            I-PER        I-ORG\n",
      "##vor           I-PER        I-ORG\n",
      "##ous           I-PER        I-ORG\n",
      "Plant           I-PER        I-ORG\n",
      "News            I-PER        I-ORG\n",
      "##lette         I-PER        I-ORG\n",
      "##r             I-PER        I-ORG\n",
      "\n",
      "Changes for example row 6482:\n",
      "Token           OLD label    NEW label\n",
      "Seven           B-ORG        B-LOC\n",
      "##ia            I-ORG        I-LOC\n",
      "g               I-ORG        I-LOC\n",
      "##are           I-ORG        I-LOC\n",
      "##ga            I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 7517:\n",
      "Token           OLD label    NEW label\n",
      "New             B-PER        B-ORG\n",
      "York            I-PER        I-ORG\n",
      "City            I-PER        I-ORG\n",
      "Police          I-PER        I-ORG\n",
      "Department      I-PER        I-ORG\n",
      "Transportation  I-PER        I-ORG\n",
      "Bureau          I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 2340:\n",
      "Token           OLD label    NEW label\n",
      "Salon           B-ORG        B-LOC\n",
      "##ga            I-ORG        I-LOC\n",
      "National        I-ORG        I-LOC\n",
      "Park            I-ORG        I-LOC\n",
      "[SEP]           I-ORG        B-LOC\n",
      "\n",
      "Changes for example row 4339:\n",
      "Token           OLD label    NEW label\n",
      "Gmina           B-ORG        B-LOC\n",
      "Spy             I-ORG        I-LOC\n",
      "##t             I-ORG        I-LOC\n",
      "##ko            I-ORG        I-LOC\n",
      "##wi            I-ORG        I-LOC\n",
      "##ce            I-ORG        I-LOC\n",
      ",               I-ORG        O\n",
      "Now             B-ORG        B-LOC\n",
      "##y             I-ORG        I-LOC\n",
      "Ta              I-ORG        I-LOC\n",
      "##rg            I-ORG        I-LOC\n",
      "County          I-ORG        I-LOC\n",
      "[SEP]           I-ORG        I-LOC\n",
      "\n",
      "Changes for example row 2287:\n",
      "Token           OLD label    NEW label\n",
      "[CLS]           I-MISC       O\n",
      "Saudi           B-MISC       B-PER\n",
      "de              I-MISC       I-PER\n",
      "##tain          I-MISC       I-PER\n",
      "##ees           I-MISC       I-PER\n",
      "at              I-MISC       I-PER\n",
      "G               I-MISC       I-PER\n",
      "##uant          I-MISC       I-PER\n",
      "##ana           I-MISC       I-PER\n",
      "##mo            I-MISC       I-PER\n",
      "Bay             I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 4040:\n",
      "Token           OLD label    NEW label\n",
      "J               B-MISC       B-PER\n",
      ".               B-MISC       I-PER\n",
      "W               I-MISC       I-PER\n",
      ".               I-MISC       I-PER\n",
      "Storm           I-MISC       I-PER\n",
      "[SEP]           I-MISC       I-PER\n",
      "\n",
      "Changes for example row 9197:\n",
      "Token           OLD label    NEW label\n",
      "Fred            B-MISC       B-PER\n",
      "Williams        I-MISC       I-PER\n",
      "\n",
      "Changes for example row 8830:\n",
      "Token           OLD label    NEW label\n",
      "Republic        B-PER        B-ORG\n",
      "Bank            I-PER        I-ORG\n",
      "Ban             B-PER        B-ORG\n",
      "##co            O            I-ORG\n",
      "B               I-PER        I-ORG\n",
      "##HD            I-PER        I-ORG\n",
      "\n",
      "Changes for example row 4304:\n",
      "Token           OLD label    NEW label\n",
      "Knights         B-PER        B-ORG\n",
      "of              I-PER        I-ORG\n",
      "Columbus        I-PER        I-ORG\n",
      "\n",
      "Changes for example row 9577:\n",
      "Token           OLD label    NEW label\n",
      "RB              B-PER        B-ORG\n",
      "-               I-PER        I-ORG\n",
      "26              I-PER        I-ORG\n",
      "##B             I-PER        I-ORG\n",
      "In              I-PER        I-ORG\n",
      "##vade          I-PER        I-ORG\n",
      "##r             I-PER        I-ORG\n",
      "\n",
      "Changes for example row 7019:\n",
      "Token           OLD label    NEW label\n",
      "List            B-PER        B-ORG\n",
      "of              I-PER        I-ORG\n",
      "mountains       I-PER        I-ORG\n",
      "in              I-PER        I-ORG\n",
      "Maine           I-PER        I-ORG\n",
      "[SEP]           I-PER        I-ORG\n",
      "\n",
      "Changes for example row 9560:\n",
      "Token           OLD label    NEW label\n",
      "Ex              B-PER        B-ORG\n",
      "##cel           I-PER        I-ORG\n",
      "##sio           I-PER        I-ORG\n",
      "##r             I-PER        I-ORG\n",
      "Rotterdam       I-PER        I-ORG\n"
     ]
    }
   ],
   "source": [
    "changes = compare_before_and_after(fine_tuned_model,fine_tuned_base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37035302-c9a6-454b-87fa-32f77bf85542",
   "metadata": {},
   "source": [
    "After fixing the comparison function, the properly fine-tuned bert-base-cased model shows clear  improvements over the mismatched DSLIM model. The fine-tuned model correctly converts many wrong MISC → PER, ORG → LOC, and PER → ORG predictions, showing that it has truly learned WikiANN’s label conventions.\n",
    "Now let's evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79471928-3c99-4c7a-bdd2-3bcef5d76dd6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb4570bf-c5ca-44cf-808b-44fb597be962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 6.34kB [00:00, 17.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b20d0ccc-9a63-4942-bfa9-04e34a58b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_wikiann(\n",
    "    model,\n",
    "    tokenized_dataset,\n",
    "    label_list,\n",
    "    tokenizer,\n",
    "    collapse_misc=False,\n",
    "    batch_size=16,\n",
    "    output_dir=\"./tmp-eval\"\n",
    "):\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        logging_strategy=\"no\",\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    eval_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        data_collator=default_data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    predictions = eval_trainer.predict(tokenized_dataset)\n",
    "\n",
    "    logits = predictions.predictions\n",
    "    true_label_ids = predictions.label_ids\n",
    "    pred_label_ids = np.argmax(logits, axis=-1)\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    id2label = model.config.id2label\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_label_ids, pred_label_ids):\n",
    "        ex_true = []\n",
    "        ex_pred = []\n",
    "\n",
    "        for t_id, p_id in zip(true_seq, pred_seq):\n",
    "            if t_id == -100:\n",
    "                continue\n",
    "\n",
    "            true_label = label_list[t_id]\n",
    "            pred_label = id2label[p_id]\n",
    "\n",
    "            if collapse_misc and \"MISC\" in pred_label:\n",
    "                pred_label = \"O\"\n",
    "\n",
    "            ex_true.append(true_label)\n",
    "            ex_pred.append(pred_label)\n",
    "\n",
    "        if ex_true:\n",
    "            all_true_labels.append(ex_true)\n",
    "            all_pred_labels.append(ex_pred)\n",
    "\n",
    "    metrics = seqeval.compute(\n",
    "        predictions=all_pred_labels,\n",
    "        references=all_true_labels\n",
    "    )\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40a9d244-8f63-4865-b808-2107958ed3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10024/156498845.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter-server/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dslim/bert-base-NER on WikiANN (MISC -> O):\n",
      "overall_precision: 0.0500208420175073\n",
      "overall_recall: 0.03438888092849979\n",
      "overall_f1: 0.04075740850810903\n",
      "overall_accuracy: 0.5208027288798147\n"
     ]
    }
   ],
   "source": [
    "metrics_dslim_orig = evaluate_model_on_wikiann(\n",
    "    model=model,\n",
    "    tokenized_dataset=tokenized_wikiann[\"test\"],\n",
    "    label_list=label_list,\n",
    "    tokenizer=tokenizer,\n",
    "    collapse_misc=True,\n",
    "    output_dir=\"./eval-dslim-orig\"\n",
    ")\n",
    "\n",
    "print(\"Original dslim/bert-base-NER on WikiANN (MISC -> O):\")\n",
    "for k in [\"overall_precision\", \"overall_recall\", \"overall_f1\", \"overall_accuracy\"]:\n",
    "    print(f\"{k}: {metrics_dslim_orig[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4bfec0aa-1e7a-4f39-ad7d-6f93ec31c0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10024/156498845.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter-server/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dslim fine-tuned 3 epochs on WikiANN (MISC -> O):\n",
      "overall_precision: 0.0500208420175073\n",
      "overall_recall: 0.03438888092849979\n",
      "overall_f1: 0.04075740850810903\n",
      "overall_accuracy: 0.5208027288798147\n"
     ]
    }
   ],
   "source": [
    "metrics_dslim_ft = evaluate_model_on_wikiann(\n",
    "    model=fine_tuned_model,\n",
    "    tokenized_dataset=tokenized_wikiann[\"test\"],\n",
    "    label_list=label_list,\n",
    "    tokenizer=tokenizer,\n",
    "    collapse_misc=True,\n",
    "    output_dir=\"./eval-dslim-ft-3ep\"\n",
    ")\n",
    "\n",
    "print(\"\\ndslim fine-tuned 3 epochs on WikiANN (MISC -> O):\")\n",
    "for k in [\"overall_precision\", \"overall_recall\", \"overall_f1\", \"overall_accuracy\"]:\n",
    "    print(f\"{k}: {metrics_dslim_ft[k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10253a76-9edd-431f-80e3-cb6b797f534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10024/156498845.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Properly fine-tuned bert-base-cased on WikiANN:\n",
      "overall_precision: 0.8336023580602148\n",
      "overall_recall: 0.850981515976501\n",
      "overall_f1: 0.8422022902116495\n",
      "overall_accuracy: 0.9342429599382516\n"
     ]
    }
   ],
   "source": [
    "metrics_base_ft = evaluate_model_on_wikiann(\n",
    "    model=fine_tuned_base_model,\n",
    "    tokenized_dataset=tokenized_wikiann[\"test\"],\n",
    "    label_list=label_list,\n",
    "    tokenizer=tokenizer,\n",
    "    collapse_misc=False,\n",
    "    output_dir=\"./eval-base-ft\"\n",
    ")\n",
    "\n",
    "print(\"\\nProperly fine-tuned bert-base-cased on WikiANN:\")\n",
    "for k in [\"overall_precision\", \"overall_recall\", \"overall_f1\", \"overall_accuracy\"]:\n",
    "#    print(f\"{k}: {metrics_base_ft[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bab7d-dbe7-4588-9170-3742f7baa8cd",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The experiments clearly demonstrates the impact of correct label-space alignment in NER fine-tuning.\n",
    "The pretrained dslim/bert-base-NER model performed very poorly on WikiANN (F1 ≈ 0.04) because its classifier head expects four CoNLL entity types, including MISC, which WikiANN does not use. When this mismatched model was fine-tuned for 3 epochs on WikiANN, the performance remained identical—showing that the head could not learn meaningful updates because one of its label dimensions received no supervision and the remaining ones were misaligned with the dataset.\n",
    "\n",
    "\n",
    "But when BERT base model was initialized with a properly defined 7-label WikiANN classification head, the model converged successfully. After 5 epochs of fine-tuning, the new model achieved strong performance:\n",
    "* Precision: 0.83\n",
    "* Recall: 0.85\n",
    "* F1: 0.84\n",
    "* Accuracy: 0.93\n",
    " \n",
    "it means that fine-tuning cannot succeed when the model’s label space does not match the dataset. Once the label mismatch was removed, BERT learned WikiANN effectively and achieved high-quality NER performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
